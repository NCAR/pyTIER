{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc6051e",
   "metadata": {},
   "source": [
    "\n",
    "# Requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4961b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "from statistics import mode, mean\n",
    "import shutil\n",
    "import os\n",
    "from itertools import combinations\n",
    "from scipy.interpolate import griddata\n",
    "from os import path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a2946",
   "metadata": {},
   "source": [
    "# Driver for the Topographically InformEd Regression (TIER) tool\n",
    "\n",
    "This tool is built on the concept that geophyiscal attributes contain information useful to predict the spatial distribution of meteorological variables (e.g. Daly et al. 1994,2002,2007,2008; Thornton et al. 1999; Clark and Slater 2006; Carrera-Hernandez and Gaskin 2007; Tobin et al. 2011; Bardossy and Pegram 2013; Newman et al. 2015).\n",
    "\n",
    "A pre-processed DEM file (see tierPreprocessing.m) and input station data are used to create monthly climatological meteorological fields over a domain.  \n",
    "\n",
    "Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "This file is part of TIER.\n",
    "\n",
    "TIER is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or(at your option) any later version.\n",
    "TIER is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty o MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd1af0",
   "metadata": {},
   "source": [
    "# User determines the controlName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb9aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of your control file: tierControl.txt\n"
     ]
    }
   ],
   "source": [
    "controlName = input('Enter the name of your control file: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af9bd7",
   "metadata": {},
   "source": [
    "# readControl:\n",
    "  \n",
    "* **Reads a text control file for TIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9782f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readControl(controlName):\n",
    "    \n",
    "    \"\"\"\n",
    "    readControl reads a text control file for TIER\n",
    "    TIER - Topographically InformEd Regression\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "     Input:controlName, string, the name of the grid file\n",
    "\n",
    "     Output:controlVars, structure\n",
    "     , stucture holding all control variables\n",
    "                           \n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    " \n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "    \"\"\"\n",
    "   #open control file\n",
    "    fid = open(controlName,'r')\n",
    "    #read data\n",
    "    data = np.loadtxt(fid, delimiter=',',skiprows=1,dtype=str, usecols=[0,1,2])\n",
    "    #close control file\n",
    "    fid.close()\n",
    "\n",
    "    class structtype():\n",
    "        pass\n",
    "    controlVars = structtype()\n",
    "\n",
    "    #run through all lines in control file\n",
    "    for i in range(0,len(data)):\n",
    "        #test string name and place in appropriate named variable\n",
    "        if [row[0] for row in data][i]== 'gridName':\n",
    "            controlVars.gridName = [row[1] for row in data][i].strip()\n",
    "\n",
    "        elif [row[0] for row in data][i]=='stationFileList':\n",
    "            controlVars.stationFileList  = [row[1] for row in data][i].strip()\n",
    "\n",
    "        elif [row[0] for row in data][i]=='stationDataPath':\n",
    "            controlVars.stationDataPath = [row[1] for row in data][i].strip()\n",
    "\n",
    "        elif [row[0] for row in data][i]=='outputName':\n",
    "            controlVars.outputName = [row[1] for row in data][i].strip()\n",
    "\n",
    "        elif [row[0] for row in data][i]=='parameterFile':\n",
    "            controlVars.parameterFile= [row[1] for row in data][i].strip()\n",
    "\n",
    "        elif [row[0] for row in data][i]=='variableEstimated':\n",
    "            controlVars.variableEstimated = [row[1] for row in data][i].strip()\n",
    "\n",
    "        elif [row[0] for row in data][i]=='defaultTempLapse':\n",
    "            controlVars.defaultTempLapse = [row[1] for row in data][i].strip()\n",
    "\n",
    "        else:\n",
    "            #throw error if unknown string\n",
    "            print('Unknown control file option: ' +[row[0] for row in data][i])\n",
    "\n",
    "    return controlVars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54db59f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.readControl.<locals>.structtype at 0x1b41565dd00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read control file\n",
    "controlVars = readControl(controlName)\n",
    "controlVars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a7da0",
   "metadata": {},
   "source": [
    "# initPreprocessParameters:\n",
    "* **Initalizes TIER parameters to defaults**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b687a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParameters(varEstimated):\n",
    "    \"\"\"\n",
    "\n",
    "     initParameters initalizes TIER parameters to defaults\n",
    "     TIER - Topographically InformEd Regression\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Output: parameters, structure, structure holding all TIER parameters\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    class structtype():\n",
    "        pass\n",
    "    parameters = structtype()\n",
    "    #initialize all parameters to initial default value\n",
    "    parameters.nMaxNear = 7                           #number\n",
    "    parameters.nMinNear = 3                           #number\n",
    "    parameters.maxDist = 250                          #km\n",
    "    parameters.minSlope = 0.5                         #normalized for precipitation\n",
    "    parameters.maxInitialSlope = 4.25                 #normalized\n",
    "    parameters.maxFinalSlope = 3.0                    #normalized\n",
    "    parameters.maxSlopeLower = 0                      #K/km\n",
    "    parameters.maxSlopeUpper = 20                     #K/km\n",
    "    parameters.defaultSlope = 1.3                     #normalized\n",
    "    parameters.topoPosMinDiff = 500                   #m\n",
    "    parameters.topoPosMaxDiff = 5000                  #m\n",
    "    parameters.topoPosExp = 0.7                       # -\n",
    "    parameters.coastalExp = 1.0                       # -\n",
    "    parameters.layerExp = 0.5                         # -\n",
    "    parameters.distanceWeightScale = 16000            # -\n",
    "    parameters.distanceWeightExp = 2                  # -\n",
    "    parameters.maxGrad = 2.5                          # normalized slope per grid cell\n",
    "    parameters.bufferSlope = 0.02                     # normalized\n",
    "    parameters.minElev = 100                          # m\n",
    "    parameters.minElevDiff = 500                      # m\n",
    "    parameters.filterSize = 60                        # grid cells\n",
    "    parameters.filterSpread = 40                      # -\n",
    "    parameters.covWindow = 10                         # grid cells\n",
    "    parameters.recomputeDefaultPrecipSlope = 'false'  #logical\n",
    "    parameters.recomputeDefaultTempSlope   = 'false'  #logical\n",
    "\n",
    "    #initialize variables based on meteorological variable being regressed\n",
    "    if varEstimated=='tmax' or varEstimated=='tmin':\n",
    "        #temperature specific initialization values here\n",
    "        parameters.nMaxNear = 30                 #number\n",
    "        parameters.nMinNear = 3                  #number\n",
    "        parameters.maxDist = 300                 #km\n",
    "        parameters.minSlope = -10                #K/km\n",
    "        parameters.maxSlopeLower = 0             #K/km\n",
    "        parameters.maxSlopeUpper = 20            #K/km\n",
    "        parameters.defaultSlope = -5             #normalized\n",
    "        parameters.topoPosMinDiff = 0            #m \n",
    "        parameters.topoPosMaxDiff = 500          #m\n",
    "        parameters.topoPosExp = 0.50             # -\n",
    "        parameters.coastalExp = 1.0              # -\n",
    "        parameters.layerExp = 4.0                # -\n",
    "        parameters.distanceWeightScale = 20000   # - \n",
    "        \n",
    "#     elif varEstimated =='precip':\n",
    "#       #precipitation specific initialization values here \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6221fb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initalize parameters to default values\n",
    "parameters = initParameters(controlVars.variableEstimated)\n",
    "parameters.nMaxNear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7c4dc",
   "metadata": {},
   "source": [
    "# readParameters:\n",
    "* **Reads a text parameter file for TIER**\n",
    "* **Overrides the default values if parameters are present in parameter file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e0a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readParameters(parameterFile,parameters):\n",
    "    \"\"\"\n",
    "    \n",
    "    readParameters reads a text parameter file for TIER and overrides the default values \n",
    "    if parameters are present in parameter file\n",
    "\n",
    "     TIER - Topographically InformEd Regression\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "     Input: parameterFile, string, the name of the TIER parameter file\n",
    "      parameters, structure, structure holding all TIER parameters\n",
    "\n",
    "     Output:parameters, structure, structure holding all TIER parameters\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "  #open parameter file\n",
    "    fid = open(parameterFile,'r')\n",
    "    #read data\n",
    "    data = np.loadtxt(fid, delimiter=',',skiprows=1,dtype=str, usecols=[0,1,2])\n",
    "    #close control file\n",
    "    fid.close()   \n",
    "    \n",
    "    #run through all lines in parameter file\n",
    "    for i in range(0,len(data)):\n",
    "        #test string name and place in appropriate named variable\n",
    "        if [row[0] for row in data][i]== 'nMaxNear':\n",
    "        #maximum number of nearby stations to consider            \n",
    "            parameters.nMaxNear = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]== 'nMinNear':\n",
    "            #minimum number of nearby stations needed for slope regression\n",
    "            parameters.nMinNear = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='maxDist':\n",
    "            #maximum distance to consider stations\n",
    "            parameters.maxDist = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='minSlope':\n",
    "            #minimum valid slope value (normalized for precipitation, physical units for temperature)\n",
    "            parameters.minSlope = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='maxInitialSlope':\n",
    "            #maximum valid initial pass normalized slope for precipitation\n",
    "            parameters.maxInitialSlope = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='maxFinalSlope':\n",
    "            #maximum valid final adjusted normalized slope for precipitation\n",
    "            parameters.maxFinalSlope = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='maxSlopeLower':\n",
    "            #maximum valid slope for temperature in lower atmospheric layer (inversion layer, allows for strong inversions)\n",
    "            parameters.maxSlopeLower = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='maxSlopeUpper':\n",
    "            #maximum valid slope for temperature in upper layer (free atmosphere, up to isothermal allowed)\n",
    "            parameters.maxSlopeUpper = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='defaultSlope':\n",
    "            #default slope value (normalized for precipitation, physical units for temperature)\n",
    "            parameters.defaultSlope = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='topoPosMinDiff':\n",
    "            #minimum elevation difference used to adjust topographic position weights\n",
    "            parameters.topoPosMinDiff = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='topoPosMaxDiff':\n",
    "            #maximum elevation difference for stations to receive topographic position weighting\n",
    "            parameters.topoPosMaxDiff = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='topoPosExp':\n",
    "            #exponent to adjust topographic position weighting function\n",
    "            parameters.topoPosExp = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='coastalExp':\n",
    "            #exponent to adjust distance to coast weighting function\n",
    "            parameters.coastalExp = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='layerExp':\n",
    "            #exponent to adjust atmospheric layer weighting function\n",
    "            parameters.layerExp = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='distanceWeightScale':\n",
    "            #scale parameter in Barnes (1964) distance weighting function\n",
    "            parameters.distanceWeightScale = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='distanceWeightExp':\n",
    "            #exponent in Barnes (1964) distance weighting function\n",
    "            parameters.distanceWeightExp = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='maxGrad':\n",
    "            #maximum allowable normalized precipitation slope gradient between grid cells\n",
    "            parameters.maxGrad = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='bufferSlope':\n",
    "            #a buffer parameter when computing precipitaiton slope feathering\n",
    "            parameters.bufferSlope = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]== 'minElev':\n",
    "            #minimum elevation considered when feathering precipitation\n",
    "            parameters.minElev = float([row[1] for row in data][i].strip())/1000 #convert m to km\n",
    "        elif [row[0] for row in data][i]=='minElevDiff':\n",
    "            #minimum elevation difference across precipitation considered for feathering precipitation\n",
    "            parameters.minElevDiff = float([row[1] for row in data][i].strip())/1000 #convert m to km\n",
    "        elif [row[0] for row in data][i]=='recomputeDefaultPrecipSlope':\n",
    "            #logical to indicate if the default slope should be\n",
    "            #recomputed using the domain valid regression points            \n",
    "            parameters.recomputeDefaultPrecipSlope = [row[1] for row in data][i].strip()\n",
    "        elif [row[0] for row in data][i]=='recomputeDefaultTempSlope':\n",
    "            #logical to indicate if the default slope should be\n",
    "            #recomputed using the domain valid regression points\n",
    "            parameters.recomputeDefaultTempSlope = [row[1] for row in data][i].strip()\n",
    "        elif [row[0] for row in data][i]=='filterSize':\n",
    "            #size of low pass filter (grid points) used in computing updated slopes and uncertainty estimates\n",
    "            parameters.filterSize = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='filterSpread':\n",
    "            #spread of low-pass filter power used in computing updated slopes and uncertainty estimates\n",
    "            parameters.filterSpread = float([row[1] for row in data][i].strip())\n",
    "        elif [row[0] for row in data][i]=='covWindow':\n",
    "            #window for local covariance calculation for the baseInterp and slope uncertainty components.  Used in the final uncertainty estimation routine\n",
    "            parameters.covWindow = float([row[1] for row in data][i].strip())\n",
    "        \n",
    "        else:\n",
    "            #throw error if unknown string\n",
    "            print('Unknown parameter name : '+[row[0] for row in data][i])\n",
    "                  \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0afaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read user defined TIER parameter file\n",
    "parameters = readParameters(controlVars.parameterFile,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52fd4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.nMinNear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f8106",
   "metadata": {},
   "source": [
    "# readGrid:\n",
    "* **reads a netcdf grid file for the TIER code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c72f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGrid(gridName):\n",
    "\n",
    "    \"\"\"\n",
    "     readGrid reads a netcdf grid file for the TIER code\n",
    "     TIER - Topographically InformEd Regression\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "     Input:gridName, string, the name of the grid file\n",
    "\n",
    "     Output:grid, structure, structure holding DEM, geophysical attributes\n",
    "                       and related variables\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    class structtype():\n",
    "        pass\n",
    "    grid = structtype()\n",
    "    \n",
    "    #loading dataset by passing a NetCDF file path\n",
    "    ds = Dataset(gridName)\n",
    "    \n",
    "    #read latitude and longitude\n",
    "    grid.lat = ds['latitude'][:]\n",
    "    grid.lon = ds['longitude'][:]\n",
    "    #grid spacing\n",
    "    gridUnits = ds['dx'].units\n",
    "    \n",
    "    if gridUnits.lower()=='degrees':\n",
    "        grid.dx = ds['dx'][:]\n",
    "        #convert to km (roughly)\n",
    "        \n",
    "        #grid lower left lat,lon\n",
    "        startLon = ds['startx'][:]\n",
    "        startLat = ds['starty'][:]\n",
    "\n",
    "\n",
    "        # phi = 90 - latitude\n",
    "        phi1 = np.deg2rad(90.0 - startLat)\n",
    "        phi2 = np.deg2rad(90.0 - (startLat+grid.dx))\n",
    "\n",
    "        # theta = longitude\n",
    "        theta1 = np.deg2rad(startLon)\n",
    "        theta2 = np.deg2rad(startLon+grid.dx)\n",
    "\n",
    "\n",
    "        # kmPerLat = math.sqrt((startLat - (startLat+grid.dx))**2 + (startLon- (startLon+grid.dx))**2)\n",
    "        kmPerLat = sqrt((phi1 - phi2)**2 + (theta1- theta2)**2)*6371\n",
    "        # distance = earth radius * radians\n",
    "        \n",
    "        # distance = earth radius * radians\n",
    "        Earth_radius = 6371\n",
    "        km2rad= kmPerLat/Earth_radius\n",
    "        gridDist = np.rad2deg(km2rad)\n",
    "        \n",
    "        #grid distance in km roughly\n",
    "        grid.dx = (grid.dx*kmPerLat)/sqrt(gridDist**2)\n",
    "        \n",
    "    elif gridUnits.lower() =='km':\n",
    "        grid.dx = ds['dx'] \n",
    "    elif gridUnits.lower() =='m':\n",
    "        grid.dx = ds['dx']/1000 #convert m to km\n",
    "    else:\n",
    "        print('Unknown grid dx units: ' + gridUnits+'\\n')\n",
    "    \n",
    "    #read valid grid point mask\n",
    "    grid.mask = ds['mask'][:] \n",
    "    #read DEM\n",
    "    grid.dem = ds['elev'][:]\n",
    "    #read smoothed DEM\n",
    "    grid.smoothDem = ds['smooth_elev'][:]\n",
    "    #read distance to coast\n",
    "    grid.distToCoast = ds['dist_to_coast'][:]\n",
    "    #read inversion layer\n",
    "    grid.layerMask = ds['inversion_layer'][:]\n",
    "    #read topographic position\n",
    "    grid.topoPosition = ds['topo_position'][:]\n",
    "\n",
    "    #convert DEM to km\n",
    "    grid.dem = grid.dem/1000.0\n",
    "    \n",
    "    #read slope facet\n",
    "    grid.facet = ds['facet'][:]\n",
    "    #double check missing data points, reset very low DEM values to missing\n",
    "    grid.facet[grid.dem < -100] = -999\n",
    "    \n",
    "    #set grid size variables\n",
    "    (grid.nc,grid.nr) = np.shape(grid.lat)\n",
    "    \n",
    "    return grid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d360a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., 0.9143148502111434, 0.859966135263443,\n",
       "         0.6705146512389183],\n",
       "        [--, --, --, ..., 0.8751585264205932, 0.8193460587859154,\n",
       "         0.636209140777588],\n",
       "        [--, --, --, ..., 0.8987839505672455, 0.8228409062623978,\n",
       "         0.6274272040724754],\n",
       "        ...,\n",
       "        [--, --, --, ..., 1.2244391309022904, 1.106477852642536,\n",
       "         0.8316656767725944],\n",
       "        [--, --, --, ..., 1.1270257021784782, 1.0352777718901633,\n",
       "         0.79061106133461],\n",
       "        [--, --, --, ..., 1.0157711544036865, 0.9459361028075218,\n",
       "         0.7316063257455826]],\n",
       "  mask=[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False]],\n",
       "  fill_value=-999.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read grid file\n",
    "grid = readGrid(controlVars.gridName)\n",
    "grid.smoothDemKM = grid.smoothDem/1000\n",
    "grid.smoothDemKM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046794b",
   "metadata": {},
   "source": [
    "# allocateMetVars:\n",
    "* **allocates memory for met variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a2bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocateMetVars(nc,nr):\n",
    "    \"\"\"\n",
    "    \n",
    "    allocateMetVars allocates memory for met variables\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input:nr, integer, number of rows in grid\n",
    "            nc, integer, number of columns in grid\n",
    "\n",
    "      Output:metGrid, structure, structure housing all grids related to\n",
    "                           met field generation\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "     \n",
    "     \"\"\"\n",
    "    class structtype():\n",
    "        pass\n",
    "    metGrid = structtype()\n",
    "    #allocate space for grids\n",
    "    \n",
    "    metGrid.rawField         = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.intercept        = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.slope            = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.normSlope        = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.baseInterpField  = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.baseInterpElev   = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.baseInterpUncert = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.slopeUncert      = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.normSlopeUncert  = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.defaultSlope     = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.finalSlope       = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.finalField       = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.totalUncert      = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.relUncert        = np.zeros([nc,nr])* np.nan\n",
    "    metGrid.validRegress     = np.zeros([nc,nr])* np.nan\n",
    "\n",
    "    return metGrid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5407e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocate space for output variables\n",
    "metGrid = allocateMetVars(grid.nc,grid.nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c211e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(metGrid.normSlopeUncert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb577cf",
   "metadata": {},
   "source": [
    "# readInputStations:\n",
    "* **reads the input point station metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c834842",
   "metadata": {},
   "outputs": [],
   "source": [
    " def readInputStations(controlVars):\n",
    "    \"\"\"\"\n",
    "    readInputStations reads the input point station metadata\n",
    "    and station data for TIER\n",
    "    TIER - Topographically InformEd Regression\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "     Input:   stationFileList, string, the name of the station metadata file\n",
    "              stationDataPath, string, path to location of station data\n",
    "              controlVars, structure, structure holding control variables\n",
    "\n",
    "     Output: inputStations, structure, structure holding input station data, metdata, etc\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    class structtype():\n",
    "        pass\n",
    "    meta= structtype()\n",
    "    inputStations= structtype()\n",
    "    #open station list file\n",
    "    fid = open(controlVars.stationFileList,'r')\n",
    "    #read data\n",
    "    data = np.loadtxt(fid, delimiter=',',skiprows=2,dtype=str, usecols=[0,1,2,3,4,5,6,7,8])\n",
    "    #close control file\n",
    "    \n",
    "    meta.staId = [row[0].strip() for row in data]\n",
    "    meta.lat = [float(row[1].strip()) for row in data]\n",
    "    meta.lon = [float(row[2].strip()) for row in data]\n",
    "    meta.elev = [float(row[3].strip()) for row in data]\n",
    "    meta.facet = [float(row[4].strip()) for row in data]\n",
    "    meta.coastDist = [float(row[5].strip()) for row in data]\n",
    "    meta.layer = [row[6].strip() for row in data]\n",
    "    meta.topoPosition = [float(row[7].strip()) for row in data]\n",
    "    meta.staName = [row[8].strip() for row in data]\n",
    "    inputStations.meta= meta\n",
    "\n",
    "    #close control file\n",
    "    fid.close()\n",
    "\n",
    "    #set number of stations\n",
    "    nSta = len(inputStations.meta.staName)\n",
    "\n",
    "    #convert elevation to km\n",
    "    inputStations.meta.elev = [elev/1000 for elev in inputStations.meta.elev]\n",
    "\n",
    "    #allocate inputStations structure\n",
    "    inputStations.avgVar = np.zeros([nSta,1])\n",
    "\n",
    "    if controlVars.variableEstimated=='precip':\n",
    "        metVar = 'prcp'\n",
    "    elif [controlVars.variableEstimated=='tmax'] or [controlVars.variableEstimated=='tmin']:\n",
    "        metVar = np.lower(controlVars.variableEstimated)\n",
    "    metVar\n",
    "\n",
    "    #read data\n",
    "    for i in range(0,nSta):\n",
    "        print('Loading: %s\\n'%inputStations.meta.staName[i])\n",
    "        #create file name string    \n",
    "        fname= '%s%s.nc'%(controlVars.stationDataPath,inputStations.meta.staName[i])\n",
    "        #read station data\n",
    "        inputStations.avgVar[i] = Dataset(fname)[metVar][:]\n",
    "\n",
    "    return inputStations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3030a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: US1CAAL0001\n",
      "\n",
      "Loading: US1CAAL0003\n",
      "\n",
      "Loading: US1CAAL0004\n",
      "\n",
      "Loading: US1CAAL0007\n",
      "\n",
      "Loading: US1CAAL0011\n",
      "\n",
      "Loading: US1CAAL0012\n",
      "\n",
      "Loading: US1CAAM0003\n",
      "\n",
      "Loading: US1CABT0002\n",
      "\n",
      "Loading: US1CABT0007\n",
      "\n",
      "Loading: US1CACC0001\n",
      "\n",
      "Loading: US1CACC0004\n",
      "\n",
      "Loading: US1CACC0010\n",
      "\n",
      "Loading: US1CACC0011\n",
      "\n",
      "Loading: US1CACC0016\n",
      "\n",
      "Loading: US1CACC0018\n",
      "\n",
      "Loading: US1CACV0002\n",
      "\n",
      "Loading: US1CADN0001\n",
      "\n",
      "Loading: US1CAED0010\n",
      "\n",
      "Loading: US1CAFR0002\n",
      "\n",
      "Loading: US1CAFR0003\n",
      "\n",
      "Loading: US1CAFR0005\n",
      "\n",
      "Loading: US1CAFR0007\n",
      "\n",
      "Loading: US1CAFR0008\n",
      "\n",
      "Loading: US1CAHM0001\n",
      "\n",
      "Loading: US1CAHM0002\n",
      "\n",
      "Loading: US1CAHM0003\n",
      "\n",
      "Loading: US1CAHM0004\n",
      "\n",
      "Loading: US1CAHM0005\n",
      "\n",
      "Loading: US1CAHM0009\n",
      "\n",
      "Loading: US1CAHM0014\n",
      "\n",
      "Loading: US1CAHM0016\n",
      "\n",
      "Loading: US1CAHM0021\n",
      "\n",
      "Loading: US1CAHM0022\n",
      "\n",
      "Loading: US1CAHM0026\n",
      "\n",
      "Loading: US1CAHM0029\n",
      "\n",
      "Loading: US1CAHM0030\n",
      "\n",
      "Loading: US1CAHM0035\n",
      "\n",
      "Loading: US1CAHM0038\n",
      "\n",
      "Loading: US1CAIN0001\n",
      "\n",
      "Loading: US1CAIN0002\n",
      "\n",
      "Loading: US1CAKG0001\n",
      "\n",
      "Loading: US1CAKG0003\n",
      "\n",
      "Loading: US1CAKG0004\n",
      "\n",
      "Loading: US1CAKG0005\n",
      "\n",
      "Loading: US1CAKN0001\n",
      "\n",
      "Loading: US1CAKN0013\n",
      "\n",
      "Loading: US1CALK0008\n",
      "\n",
      "Loading: US1CALS0001\n",
      "\n",
      "Loading: US1CAMA0001\n",
      "\n",
      "Loading: US1CAMD0001\n",
      "\n",
      "Loading: US1CAMD0003\n",
      "\n",
      "Loading: US1CAMD0007\n",
      "\n",
      "Loading: US1CAMD0009\n",
      "\n",
      "Loading: US1CAMD0014\n",
      "\n",
      "Loading: US1CAMD0016\n",
      "\n",
      "Loading: US1CAMD0017\n",
      "\n",
      "Loading: US1CAMN0001\n",
      "\n",
      "Loading: US1CAMP0001\n",
      "\n",
      "Loading: US1CAMP0002\n",
      "\n",
      "Loading: US1CAMP0003\n",
      "\n",
      "Loading: US1CAMR0002\n",
      "\n",
      "Loading: US1CAMR0003\n",
      "\n",
      "Loading: US1CAMR0005\n",
      "\n",
      "Loading: US1CAMR0009\n",
      "\n",
      "Loading: US1CAMR0012\n",
      "\n",
      "Loading: US1CAMT0002\n",
      "\n",
      "Loading: US1CAMT0003\n",
      "\n",
      "Loading: US1CAMT0005\n",
      "\n",
      "Loading: US1CAMT0006\n",
      "\n",
      "Loading: US1CAMT0007\n",
      "\n",
      "Loading: US1CAMT0008\n",
      "\n",
      "Loading: US1CAMT0020\n",
      "\n",
      "Loading: US1CAMT0023\n",
      "\n",
      "Loading: US1CANP0003\n",
      "\n",
      "Loading: US1CANV0001\n",
      "\n",
      "Loading: US1CANV0014\n",
      "\n",
      "Loading: US1CANV0016\n",
      "\n",
      "Loading: US1CANV0022\n",
      "\n",
      "Loading: US1CANV0028\n",
      "\n",
      "Loading: US1CAPC0001\n",
      "\n",
      "Loading: US1CAPC0007\n",
      "\n",
      "Loading: US1CAPC0010\n",
      "\n",
      "Loading: US1CAPC0011\n",
      "\n",
      "Loading: US1CAPC0013\n",
      "\n",
      "Loading: US1CAPC0014\n",
      "\n",
      "Loading: US1CASA0002\n",
      "\n",
      "Loading: US1CASA0003\n",
      "\n",
      "Loading: US1CASA0005\n",
      "\n",
      "Loading: US1CASA0007\n",
      "\n",
      "Loading: US1CASA0012\n",
      "\n",
      "Loading: US1CASA0015\n",
      "\n",
      "Loading: US1CASA0029\n",
      "\n",
      "Loading: US1CASA0030\n",
      "\n",
      "Loading: US1CASC0001\n",
      "\n",
      "Loading: US1CASC0003\n",
      "\n",
      "Loading: US1CASC0005\n",
      "\n",
      "Loading: US1CASC0007\n",
      "\n",
      "Loading: US1CASC0011\n",
      "\n",
      "Loading: US1CASC0012\n",
      "\n",
      "Loading: US1CASC0015\n",
      "\n",
      "Loading: US1CASC0018\n",
      "\n",
      "Loading: US1CASC0032\n",
      "\n",
      "Loading: US1CASC0040\n",
      "\n",
      "Loading: US1CASF0004\n",
      "\n",
      "Loading: US1CASH0006\n",
      "\n",
      "Loading: US1CASH0009\n",
      "\n",
      "Loading: US1CASH0010\n",
      "\n",
      "Loading: US1CASH0011\n",
      "\n",
      "Loading: US1CASH0018\n",
      "\n",
      "Loading: US1CASH0021\n",
      "\n",
      "Loading: US1CASJ0001\n",
      "\n",
      "Loading: US1CASJ0003\n",
      "\n",
      "Loading: US1CASJ0004\n",
      "\n",
      "Loading: US1CASJ0005\n",
      "\n",
      "Loading: US1CASJ0006\n",
      "\n",
      "Loading: US1CASJ0007\n",
      "\n",
      "Loading: US1CASK0002\n",
      "\n",
      "Loading: US1CASK0003\n",
      "\n",
      "Loading: US1CASK0005\n",
      "\n",
      "Loading: US1CASL0001\n",
      "\n",
      "Loading: US1CASM0001\n",
      "\n",
      "Loading: US1CASM0006\n",
      "\n",
      "Loading: US1CASM0007\n",
      "\n",
      "Loading: US1CASM0008\n",
      "\n",
      "Loading: US1CASN0001\n",
      "\n",
      "Loading: US1CASN0004\n",
      "\n",
      "Loading: US1CASN0006\n",
      "\n",
      "Loading: US1CASN0007\n",
      "\n",
      "Loading: US1CASN0016\n",
      "\n",
      "Loading: US1CASN0023\n",
      "\n",
      "Loading: US1CASN0025\n",
      "\n",
      "Loading: US1CASN0028\n",
      "\n",
      "Loading: US1CASN0029\n",
      "\n",
      "Loading: US1CASN0031\n",
      "\n",
      "Loading: US1CASN0049\n",
      "\n",
      "Loading: US1CASN0061\n",
      "\n",
      "Loading: US1CASN0062\n",
      "\n",
      "Loading: US1CASN0063\n",
      "\n",
      "Loading: US1CASN0070\n",
      "\n",
      "Loading: US1CASN0071\n",
      "\n",
      "Loading: US1CASN0079\n",
      "\n",
      "Loading: US1CASN0080\n",
      "\n",
      "Loading: US1CASN0084\n",
      "\n",
      "Loading: US1CASN0088\n",
      "\n",
      "Loading: US1CASN0089\n",
      "\n",
      "Loading: US1CASN0090\n",
      "\n",
      "Loading: US1CASS0001\n",
      "\n",
      "Loading: US1CAST0002\n",
      "\n",
      "Loading: US1CAST0004\n",
      "\n",
      "Loading: US1CAST0005\n",
      "\n",
      "Loading: US1CASZ0006\n",
      "\n",
      "Loading: US1CASZ0007\n",
      "\n",
      "Loading: US1CASZ0009\n",
      "\n",
      "Loading: US1CASZ0021\n",
      "\n",
      "Loading: US1CASZ0024\n",
      "\n",
      "Loading: US1CATL0002\n",
      "\n",
      "Loading: US1CATY0003\n",
      "\n",
      "Loading: US1CATY0011\n",
      "\n",
      "Loading: US1CAYB0001\n",
      "\n",
      "Loading: US1CAYL0001\n",
      "\n",
      "Loading: US1CAYL0002\n",
      "\n",
      "Loading: US1CAYL0006\n",
      "\n",
      "Loading: US1CAYL0007\n",
      "\n",
      "Loading: US1CAYL0009\n",
      "\n",
      "Loading: US1CAYL0010\n",
      "\n",
      "Loading: US1NVCH0002\n",
      "\n",
      "Loading: US1NVCH0005\n",
      "\n",
      "Loading: US1NVDG0002\n",
      "\n",
      "Loading: US1NVDG0004\n",
      "\n",
      "Loading: US1NVDG0006\n",
      "\n",
      "Loading: US1NVDG0011\n",
      "\n",
      "Loading: US1NVLY0003\n",
      "\n",
      "Loading: US1NVLY0009\n",
      "\n",
      "Loading: US1NVLY0013\n",
      "\n",
      "Loading: US1NVWH0002\n",
      "\n",
      "Loading: US1NVWH0003\n",
      "\n",
      "Loading: US1NVWH0004\n",
      "\n",
      "Loading: US1NVWH0011\n",
      "\n",
      "Loading: US1NVWH0017\n",
      "\n",
      "Loading: US1NVWH0019\n",
      "\n",
      "Loading: US1NVWH0025\n",
      "\n",
      "Loading: US1NVWH0031\n",
      "\n",
      "Loading: US1NVWH0035\n",
      "\n",
      "Loading: US1NVWH0057\n",
      "\n",
      "Loading: US1NVWH0059\n",
      "\n",
      "Loading: US1NVWH0062\n",
      "\n",
      "Loading: US1NVWH0064\n",
      "\n",
      "Loading: US1NVWH0078\n",
      "\n",
      "Loading: US1NVWH0079\n",
      "\n",
      "Loading: US1NVWH0086\n",
      "\n",
      "Loading: US1NVWH0087\n",
      "\n",
      "Loading: US1NVWH0093\n",
      "\n",
      "Loading: US1NVWH0096\n",
      "\n",
      "Loading: US1NVWH0099\n",
      "\n",
      "Loading: US1NVWH0100\n",
      "\n",
      "Loading: US1ORCY0001\n",
      "\n",
      "Loading: US1ORCY0004\n",
      "\n",
      "Loading: US1ORCY0006\n",
      "\n",
      "Loading: US1ORCY0007\n",
      "\n",
      "Loading: US1ORCY0009\n",
      "\n",
      "Loading: US1ORDG0012\n",
      "\n",
      "Loading: US1ORJC0001\n",
      "\n",
      "Loading: US1ORJC0002\n",
      "\n",
      "Loading: US1ORJC0005\n",
      "\n",
      "Loading: US1ORJC0008\n",
      "\n",
      "Loading: US1ORJC0011\n",
      "\n",
      "Loading: US1ORJC0012\n",
      "\n",
      "Loading: US1ORJC0013\n",
      "\n",
      "Loading: US1ORJC0014\n",
      "\n",
      "Loading: US1ORJC0016\n",
      "\n",
      "Loading: US1ORJC0018\n",
      "\n",
      "Loading: US1ORJC0026\n",
      "\n",
      "Loading: US1ORJC0027\n",
      "\n",
      "Loading: US1ORJC0029\n",
      "\n",
      "Loading: US1ORJC0038\n",
      "\n",
      "Loading: US1ORJC0039\n",
      "\n",
      "Loading: US1ORJS0001\n",
      "\n",
      "Loading: US1ORJS0005\n",
      "\n",
      "Loading: US1ORKL0004\n",
      "\n",
      "Loading: US1ORKL0005\n",
      "\n",
      "Loading: US1ORKL0014\n",
      "\n",
      "Loading: USC00040010\n",
      "\n",
      "Loading: USC00040029\n",
      "\n",
      "Loading: USC00040161\n",
      "\n",
      "Loading: USC00040212\n",
      "\n",
      "Loading: USC00040232\n",
      "\n",
      "Loading: USC00040332\n",
      "\n",
      "Loading: USC00040343\n",
      "\n",
      "Loading: USC00040372\n",
      "\n",
      "Loading: USC00040379\n",
      "\n",
      "Loading: USC00040383\n",
      "\n",
      "Loading: USC00040385\n",
      "\n",
      "Loading: USC00040444\n",
      "\n",
      "Loading: USC00040449\n",
      "\n",
      "Loading: USC00040673\n",
      "\n",
      "Loading: USC00040684\n",
      "\n",
      "Loading: USC00040693\n",
      "\n",
      "Loading: USC00040738\n",
      "\n",
      "Loading: USC00040755\n",
      "\n",
      "Loading: USC00040790\n",
      "\n",
      "Loading: USC00040819\n",
      "\n",
      "Loading: USC00040820\n",
      "\n",
      "Loading: USC00040823\n",
      "\n",
      "Loading: USC00040850\n",
      "\n",
      "Loading: USC00040931\n",
      "\n",
      "Loading: USC00040943\n",
      "\n",
      "Loading: USC00041018\n",
      "\n",
      "Loading: USC00041072\n",
      "\n",
      "Loading: USC00041080\n",
      "\n",
      "Loading: USC00041112\n",
      "\n",
      "Loading: USC00041130\n",
      "\n",
      "Loading: USC00041149\n",
      "\n",
      "Loading: USC00041159\n",
      "\n",
      "Loading: USC00041214\n",
      "\n",
      "Loading: USC00041215\n",
      "\n",
      "Loading: USC00041244\n",
      "\n",
      "Loading: USC00041277\n",
      "\n",
      "Loading: USC00041312\n",
      "\n",
      "Loading: USC00041316\n",
      "\n",
      "Loading: USC00041428\n",
      "\n",
      "Loading: USC00041476\n",
      "\n",
      "Loading: USC00041497\n",
      "\n",
      "Loading: USC00041534\n",
      "\n",
      "Loading: USC00041603\n",
      "\n",
      "Loading: USC00041606\n",
      "\n",
      "Loading: USC00041614\n",
      "\n",
      "Loading: USC00041653\n",
      "\n",
      "Loading: USC00041697\n",
      "\n",
      "Loading: USC00041700\n",
      "\n",
      "Loading: USC00041715\n",
      "\n",
      "Loading: USC00041739\n",
      "\n",
      "Loading: USC00041806\n",
      "\n",
      "Loading: USC00041838\n",
      "\n",
      "Loading: USC00041864\n",
      "\n",
      "Loading: USC00041878\n",
      "\n",
      "Loading: USC00041886\n",
      "\n",
      "Loading: USC00041907\n",
      "\n",
      "Loading: USC00041912\n",
      "\n",
      "Loading: USC00041916\n",
      "\n",
      "Loading: USC00041948\n",
      "\n",
      "Loading: USC00041967\n",
      "\n",
      "Loading: USC00041990\n",
      "\n",
      "Loading: USC00042012\n",
      "\n",
      "Loading: USC00042027\n",
      "\n",
      "Loading: USC00042081\n",
      "\n",
      "Loading: USC00042147\n",
      "\n",
      "Loading: USC00042148\n",
      "\n",
      "Loading: USC00042294\n",
      "\n",
      "Loading: USC00042331\n",
      "\n",
      "Loading: USC00042338\n",
      "\n",
      "Loading: USC00042346\n",
      "\n",
      "Loading: USC00042402\n",
      "\n",
      "Loading: USC00042456\n",
      "\n",
      "Loading: USC00042467\n",
      "\n",
      "Loading: USC00042500\n",
      "\n",
      "Loading: USC00042504\n",
      "\n",
      "Loading: USC00042506\n",
      "\n",
      "Loading: USC00042574\n",
      "\n",
      "Loading: USC00042640\n",
      "\n",
      "Loading: USC00042671\n",
      "\n",
      "Loading: USC00042728\n",
      "\n",
      "Loading: USC00042749\n",
      "\n",
      "Loading: USC00042756\n",
      "\n",
      "Loading: USC00042760\n",
      "\n",
      "Loading: USC00042920\n",
      "\n",
      "Loading: USC00042934\n",
      "\n",
      "Loading: USC00042964\n",
      "\n",
      "Loading: USC00043004\n",
      "\n",
      "Loading: USC00043038\n",
      "\n",
      "Loading: USC00043083\n",
      "\n",
      "Loading: USC00043113\n",
      "\n",
      "Loading: USC00043134\n",
      "\n",
      "Loading: USC00043157\n",
      "\n",
      "Loading: USC00043161\n",
      "\n",
      "Loading: USC00043173\n",
      "\n",
      "Loading: USC00043182\n",
      "\n",
      "Loading: USC00043191\n",
      "\n",
      "Loading: USC00043244\n",
      "\n",
      "Loading: USC00043256\n",
      "\n",
      "Loading: USC00043261\n",
      "\n",
      "Loading: USC00043320\n",
      "\n",
      "Loading: USC00043357\n",
      "\n",
      "Loading: USC00043369\n",
      "\n",
      "Loading: USC00043384\n",
      "\n",
      "Loading: USC00043417\n",
      "\n",
      "Loading: USC00043463\n",
      "\n",
      "Loading: USC00043491\n",
      "\n",
      "Loading: USC00043551\n",
      "\n",
      "Loading: USC00043573\n",
      "\n",
      "Loading: USC00043578\n",
      "\n",
      "Loading: USC00043614\n",
      "\n",
      "Loading: USC00043621\n",
      "\n",
      "Loading: USC00043647\n",
      "\n",
      "Loading: USC00043669\n",
      "\n",
      "Loading: USC00043672\n",
      "\n",
      "Loading: USC00043710\n",
      "\n",
      "Loading: USC00043714\n",
      "\n",
      "Loading: USC00043747\n",
      "\n",
      "Loading: USC00043761\n",
      "\n",
      "Loading: USC00043791\n",
      "\n",
      "Loading: USC00043800\n",
      "\n",
      "Loading: USC00043824\n",
      "\n",
      "Loading: USC00043859\n",
      "\n",
      "Loading: USC00043875\n",
      "\n",
      "Loading: USC00043878\n",
      "\n",
      "Loading: USC00043882\n",
      "\n",
      "Loading: USC00043939\n",
      "\n",
      "Loading: USC00043987\n",
      "\n",
      "Loading: USC00044025\n",
      "\n",
      "Loading: USC00044074\n",
      "\n",
      "Loading: USC00044176\n",
      "\n",
      "Loading: USC00044191\n",
      "\n",
      "Loading: USC00044232\n",
      "\n",
      "Loading: USC00044278\n",
      "\n",
      "Loading: USC00044288\n",
      "\n",
      "Loading: USC00044374\n",
      "\n",
      "Loading: USC00044484\n",
      "\n",
      "Loading: USC00044500\n",
      "\n",
      "Loading: USC00044508\n",
      "\n",
      "Loading: USC00044520\n",
      "\n",
      "Loading: USC00044523\n",
      "\n",
      "Loading: USC00044534\n",
      "\n",
      "Loading: USC00044536\n",
      "\n",
      "Loading: USC00044555\n",
      "\n",
      "Loading: USC00044577\n",
      "\n",
      "Loading: USC00044683\n",
      "\n",
      "Loading: USC00044701\n",
      "\n",
      "Loading: USC00044705\n",
      "\n",
      "Loading: USC00044712\n",
      "\n",
      "Loading: USC00044713\n",
      "\n",
      "Loading: USC00044838\n",
      "\n",
      "Loading: USC00044881\n",
      "\n",
      "Loading: USC00044890\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: USC00044957\n",
      "\n",
      "Loading: USC00044997\n",
      "\n",
      "Loading: USC00045026\n",
      "\n",
      "Loading: USC00045032\n",
      "\n",
      "Loading: USC00045100\n",
      "\n",
      "Loading: USC00045118\n",
      "\n",
      "Loading: USC00045119\n",
      "\n",
      "Loading: USC00045120\n",
      "\n",
      "Loading: USC00045123\n",
      "\n",
      "Loading: USC00045125\n",
      "\n",
      "Loading: USC00045233\n",
      "\n",
      "Loading: USC00045280\n",
      "\n",
      "Loading: USC00045311\n",
      "\n",
      "Loading: USC00045338\n",
      "\n",
      "Loading: USC00045352\n",
      "\n",
      "Loading: USC00045356\n",
      "\n",
      "Loading: USC00045360\n",
      "\n",
      "Loading: USC00045378\n",
      "\n",
      "Loading: USC00045385\n",
      "\n",
      "Loading: USC00045400\n",
      "\n",
      "Loading: USC00045449\n",
      "\n",
      "Loading: USC00045532\n",
      "\n",
      "Loading: USC00045598\n",
      "\n",
      "Loading: USC00045679\n",
      "\n",
      "Loading: USC00045756\n",
      "\n",
      "Loading: USC00045779\n",
      "\n",
      "Loading: USC00045795\n",
      "\n",
      "Loading: USC00045802\n",
      "\n",
      "Loading: USC00045853\n",
      "\n",
      "Loading: USC00045866\n",
      "\n",
      "Loading: USC00045915\n",
      "\n",
      "Loading: USC00045933\n",
      "\n",
      "Loading: USC00045941\n",
      "\n",
      "Loading: USC00046027\n",
      "\n",
      "Loading: USC00046074\n",
      "\n",
      "Loading: USC00046136\n",
      "\n",
      "Loading: USC00046144\n",
      "\n",
      "Loading: USC00046168\n",
      "\n",
      "Loading: USC00046172\n",
      "\n",
      "Loading: USC00046174\n",
      "\n",
      "Loading: USC00046194\n",
      "\n",
      "Loading: USC00046252\n",
      "\n",
      "Loading: USC00046328\n",
      "\n",
      "Loading: USC00046329\n",
      "\n",
      "Loading: USC00046336\n",
      "\n",
      "Loading: USC00046370\n",
      "\n",
      "Loading: USC00046476\n",
      "\n",
      "Loading: USC00046498\n",
      "\n",
      "Loading: USC00046506\n",
      "\n",
      "Loading: USC00046508\n",
      "\n",
      "Loading: USC00046521\n",
      "\n",
      "Loading: USC00046597\n",
      "\n",
      "Loading: USC00046598\n",
      "\n",
      "Loading: USC00046599\n",
      "\n",
      "Loading: USC00046610\n",
      "\n",
      "Loading: USC00046646\n",
      "\n",
      "Loading: USC00046650\n",
      "\n",
      "Loading: USC00046675\n",
      "\n",
      "Loading: USC00046685\n",
      "\n",
      "Loading: USC00046726\n",
      "\n",
      "Loading: USC00046730\n",
      "\n",
      "Loading: USC00046826\n",
      "\n",
      "Loading: USC00046896\n",
      "\n",
      "Loading: USC00046926\n",
      "\n",
      "Loading: USC00046943\n",
      "\n",
      "Loading: USC00046944\n",
      "\n",
      "Loading: USC00046946\n",
      "\n",
      "Loading: USC00046960\n",
      "\n",
      "Loading: USC00046962\n",
      "\n",
      "Loading: USC00047009\n",
      "\n",
      "Loading: USC00047077\n",
      "\n",
      "Loading: USC00047085\n",
      "\n",
      "Loading: USC00047096\n",
      "\n",
      "Loading: USC00047109\n",
      "\n",
      "Loading: USC00047150\n",
      "\n",
      "Loading: USC00047195\n",
      "\n",
      "Loading: USC00047253\n",
      "\n",
      "Loading: USC00047293\n",
      "\n",
      "Loading: USC00047298\n",
      "\n",
      "Loading: USC00047300\n",
      "\n",
      "Loading: USC00047339\n",
      "\n",
      "Loading: USC00047370\n",
      "\n",
      "Loading: USC00047404\n",
      "\n",
      "Loading: USC00047414\n",
      "\n",
      "Loading: USC00047581\n",
      "\n",
      "Loading: USC00047641\n",
      "\n",
      "Loading: USC00047643\n",
      "\n",
      "Loading: USC00047646\n",
      "\n",
      "Loading: USC00047668\n",
      "\n",
      "Loading: USC00047672\n",
      "\n",
      "Loading: USC00047689\n",
      "\n",
      "Loading: USC00047731\n",
      "\n",
      "Loading: USC00047767\n",
      "\n",
      "Loading: USC00047807\n",
      "\n",
      "Loading: USC00047821\n",
      "\n",
      "Loading: USC00047846\n",
      "\n",
      "Loading: USC00047851\n",
      "\n",
      "Loading: USC00047880\n",
      "\n",
      "Loading: USC00047916\n",
      "\n",
      "Loading: USC00047933\n",
      "\n",
      "Loading: USC00047965\n",
      "\n",
      "Loading: USC00048025\n",
      "\n",
      "Loading: USC00048045\n",
      "\n",
      "Loading: USC00048122\n",
      "\n",
      "Loading: USC00048135\n",
      "\n",
      "Loading: USC00048163\n",
      "\n",
      "Loading: USC00048207\n",
      "\n",
      "Loading: USC00048218\n",
      "\n",
      "Loading: USC00048273\n",
      "\n",
      "Loading: USC00048351\n",
      "\n",
      "Loading: USC00048353\n",
      "\n",
      "Loading: USC00048380\n",
      "\n",
      "Loading: USC00048406\n",
      "\n",
      "Loading: USC00048446\n",
      "\n",
      "Loading: USC00048490\n",
      "\n",
      "Loading: USC00048560\n",
      "\n",
      "Loading: USC00048580\n",
      "\n",
      "Loading: USC00048587\n",
      "\n",
      "Loading: USC00048606\n",
      "\n",
      "Loading: USC00048702\n",
      "\n",
      "Loading: USC00048713\n",
      "\n",
      "Loading: USC00048752\n",
      "\n",
      "Loading: USC00048758\n",
      "\n",
      "Loading: USC00048760\n",
      "\n",
      "Loading: USC00048826\n",
      "\n",
      "Loading: USC00048829\n",
      "\n",
      "Loading: USC00048839\n",
      "\n",
      "Loading: USC00048873\n",
      "\n",
      "Loading: USC00048917\n",
      "\n",
      "Loading: USC00048928\n",
      "\n",
      "Loading: USC00048999\n",
      "\n",
      "Loading: USC00049001\n",
      "\n",
      "Loading: USC00049026\n",
      "\n",
      "Loading: USC00049035\n",
      "\n",
      "Loading: USC00049040\n",
      "\n",
      "Loading: USC00049043\n",
      "\n",
      "Loading: USC00049053\n",
      "\n",
      "Loading: USC00049073\n",
      "\n",
      "Loading: USC00049105\n",
      "\n",
      "Loading: USC00049122\n",
      "\n",
      "Loading: USC00049124\n",
      "\n",
      "Loading: USC00049167\n",
      "\n",
      "Loading: USC00049173\n",
      "\n",
      "Loading: USC00049177\n",
      "\n",
      "Loading: USC00049185\n",
      "\n",
      "Loading: USC00049200\n",
      "\n",
      "Loading: USC00049219\n",
      "\n",
      "Loading: USC00049273\n",
      "\n",
      "Loading: USC00049298\n",
      "\n",
      "Loading: USC00049351\n",
      "\n",
      "Loading: USC00049367\n",
      "\n",
      "Loading: USC00049390\n",
      "\n",
      "Loading: USC00049440\n",
      "\n",
      "Loading: USC00049452\n",
      "\n",
      "Loading: USC00049473\n",
      "\n",
      "Loading: USC00049490\n",
      "\n",
      "Loading: USC00049499\n",
      "\n",
      "Loading: USC00049560\n",
      "\n",
      "Loading: USC00049582\n",
      "\n",
      "Loading: USC00049621\n",
      "\n",
      "Loading: USC00049671\n",
      "\n",
      "Loading: USC00049677\n",
      "\n",
      "Loading: USC00049684\n",
      "\n",
      "Loading: USC00049694\n",
      "\n",
      "Loading: USC00049699\n",
      "\n",
      "Loading: USC00049742\n",
      "\n",
      "Loading: USC00049775\n",
      "\n",
      "Loading: USC00049781\n",
      "\n",
      "Loading: USC00049792\n",
      "\n",
      "Loading: USC00049814\n",
      "\n",
      "Loading: USC00049851\n",
      "\n",
      "Loading: USC00049855\n",
      "\n",
      "Loading: USC00049859\n",
      "\n",
      "Loading: USC00049866\n",
      "\n",
      "Loading: USC00261485\n",
      "\n",
      "Loading: USC00262119\n",
      "\n",
      "Loading: USC00262394\n",
      "\n",
      "Loading: USC00262431\n",
      "\n",
      "Loading: USC00262780\n",
      "\n",
      "Loading: USC00262948\n",
      "\n",
      "Loading: USC00263090\n",
      "\n",
      "Loading: USC00263205\n",
      "\n",
      "Loading: USC00263285\n",
      "\n",
      "Loading: USC00263512\n",
      "\n",
      "Loading: USC00263515\n",
      "\n",
      "Loading: USC00264349\n",
      "\n",
      "Loading: USC00264527\n",
      "\n",
      "Loading: USC00265168\n",
      "\n",
      "Loading: USC00265191\n",
      "\n",
      "Loading: USC00265194\n",
      "\n",
      "Loading: USC00266791\n",
      "\n",
      "Loading: USC00267463\n",
      "\n",
      "Loading: USC00267612\n",
      "\n",
      "Loading: USC00267618\n",
      "\n",
      "Loading: USC00267620\n",
      "\n",
      "Loading: USC00267691\n",
      "\n",
      "Loading: USC00267693\n",
      "\n",
      "Loading: USC00267697\n",
      "\n",
      "Loading: USC00267806\n",
      "\n",
      "Loading: USC00267820\n",
      "\n",
      "Loading: USC00267953\n",
      "\n",
      "Loading: USC00268160\n",
      "\n",
      "Loading: USC00268186\n",
      "\n",
      "Loading: USC00268202\n",
      "\n",
      "Loading: USC00268761\n",
      "\n",
      "Loading: USC00268822\n",
      "\n",
      "Loading: USC00268838\n",
      "\n",
      "Loading: USC00269229\n",
      "\n",
      "Loading: USC00350036\n",
      "\n",
      "Loading: USC00350118\n",
      "\n",
      "Loading: USC00350217\n",
      "\n",
      "Loading: USC00350304\n",
      "\n",
      "Loading: USC00350854\n",
      "\n",
      "Loading: USC00350856\n",
      "\n",
      "Loading: USC00351055\n",
      "\n",
      "Loading: USC00351058\n",
      "\n",
      "Loading: USC00351149\n",
      "\n",
      "Loading: USC00351207\n",
      "\n",
      "Loading: USC00351448\n",
      "\n",
      "Loading: USC00351546\n",
      "\n",
      "Loading: USC00351574\n",
      "\n",
      "Loading: USC00351946\n",
      "\n",
      "Loading: USC00353029\n",
      "\n",
      "Loading: USC00353095\n",
      "\n",
      "Loading: USC00353232\n",
      "\n",
      "Loading: USC00353356\n",
      "\n",
      "Loading: USC00353445\n",
      "\n",
      "Loading: USC00353509\n",
      "\n",
      "Loading: USC00353692\n",
      "\n",
      "Loading: USC00354060\n",
      "\n",
      "Loading: USC00354126\n",
      "\n",
      "Loading: USC00354133\n",
      "\n",
      "Loading: USC00354403\n",
      "\n",
      "Loading: USC00354501\n",
      "\n",
      "Loading: USC00354506\n",
      "\n",
      "Loading: USC00354633\n",
      "\n",
      "Loading: USC00354634\n",
      "\n",
      "Loading: USC00354670\n",
      "\n",
      "Loading: USC00354835\n",
      "\n",
      "Loading: USC00354939\n",
      "\n",
      "Loading: USC00355055\n",
      "\n",
      "Loading: USC00355174\n",
      "\n",
      "Loading: USC00355424\n",
      "\n",
      "Loading: USC00356426\n",
      "\n",
      "Loading: USC00356795\n",
      "\n",
      "Loading: USC00356907\n",
      "\n",
      "Loading: USC00357354\n",
      "\n",
      "Loading: USC00357391\n",
      "\n",
      "Loading: USC00357668\n",
      "\n",
      "Loading: USC00357817\n",
      "\n",
      "Loading: USC00358007\n",
      "\n",
      "Loading: USC00358173\n",
      "\n",
      "Loading: USC00358420\n",
      "\n",
      "Loading: USC00358536\n",
      "\n",
      "Loading: USC00358812\n",
      "\n",
      "Loading: USC00359390\n",
      "\n",
      "Loading: USS0019K04S\n",
      "\n",
      "Loading: USS0019K07S\n",
      "\n",
      "Loading: USS0019K08S\n",
      "\n",
      "Loading: USS0019L03S\n",
      "\n",
      "Loading: USS0019L05S\n",
      "\n",
      "Loading: USS0019L06S\n",
      "\n",
      "Loading: USS0019L07S\n",
      "\n",
      "Loading: USS0019L08S\n",
      "\n",
      "Loading: USS0019L13S\n",
      "\n",
      "Loading: USS0019L17S\n",
      "\n",
      "Loading: USS0019L19S\n",
      "\n",
      "Loading: USS0019L24S\n",
      "\n",
      "Loading: USS0019L38S\n",
      "\n",
      "Loading: USS0019L39S\n",
      "\n",
      "Loading: USS0019L40S\n",
      "\n",
      "Loading: USS0020G02S\n",
      "\n",
      "Loading: USS0020G06S\n",
      "\n",
      "Loading: USS0020G09S\n",
      "\n",
      "Loading: USS0020G12S\n",
      "\n",
      "Loading: USS0020H02S\n",
      "\n",
      "Loading: USS0020H06S\n",
      "\n",
      "Loading: USS0020H12S\n",
      "\n",
      "Loading: USS0020H13S\n",
      "\n",
      "Loading: USS0020K03S\n",
      "\n",
      "Loading: USS0020K04S\n",
      "\n",
      "Loading: USS0020K05S\n",
      "\n",
      "Loading: USS0020K13S\n",
      "\n",
      "Loading: USS0020K25S\n",
      "\n",
      "Loading: USS0020K27S\n",
      "\n",
      "Loading: USS0020K30S\n",
      "\n",
      "Loading: USS0020K31S\n",
      "\n",
      "Loading: USS0020L02S\n",
      "\n",
      "Loading: USS0020L06S\n",
      "\n",
      "Loading: USS0020L10S\n",
      "\n",
      "Loading: USS0021F12S\n",
      "\n",
      "Loading: USS0021F22S\n",
      "\n",
      "Loading: USS0021G03S\n",
      "\n",
      "Loading: USS0021G04S\n",
      "\n",
      "Loading: USS0022F14S\n",
      "\n",
      "Loading: USS0022F18S\n",
      "\n",
      "Loading: USS0022F45S\n",
      "\n",
      "Loading: USS0022G12S\n",
      "\n",
      "Loading: USS0022G13S\n",
      "\n",
      "Loading: USS0022G14S\n",
      "\n",
      "Loading: USS0022G21S\n",
      "\n",
      "Loading: USS0022G24S\n",
      "\n",
      "Loading: USS0022G33S\n",
      "\n",
      "Loading: USS0023G09S\n",
      "\n",
      "Loading: USS0023G15S\n",
      "\n",
      "Loading: USW00004139\n",
      "\n",
      "Loading: USW00004222\n",
      "\n",
      "Loading: USW00023110\n",
      "\n",
      "Loading: USW00023153\n",
      "\n",
      "Loading: USW00023155\n",
      "\n",
      "Loading: USW00023157\n",
      "\n",
      "Loading: USW00023185\n",
      "\n",
      "Loading: USW00023202\n",
      "\n",
      "Loading: USW00023213\n",
      "\n",
      "Loading: USW00023225\n",
      "\n",
      "Loading: USW00023230\n",
      "\n",
      "Loading: USW00023232\n",
      "\n",
      "Loading: USW00023233\n",
      "\n",
      "Loading: USW00023234\n",
      "\n",
      "Loading: USW00023237\n",
      "\n",
      "Loading: USW00023239\n",
      "\n",
      "Loading: USW00023244\n",
      "\n",
      "Loading: USW00023254\n",
      "\n",
      "Loading: USW00023257\n",
      "\n",
      "Loading: USW00023258\n",
      "\n",
      "Loading: USW00023259\n",
      "\n",
      "Loading: USW00023271\n",
      "\n",
      "Loading: USW00023272\n",
      "\n",
      "Loading: USW00023275\n",
      "\n",
      "Loading: USW00023277\n",
      "\n",
      "Loading: USW00023285\n",
      "\n",
      "Loading: USW00023293\n",
      "\n",
      "Loading: USW00024172\n",
      "\n",
      "Loading: USW00024213\n",
      "\n",
      "Loading: USW00024215\n",
      "\n",
      "Loading: USW00024216\n",
      "\n",
      "Loading: USW00024225\n",
      "\n",
      "Loading: USW00024235\n",
      "\n",
      "Loading: USW00024257\n",
      "\n",
      "Loading: USW00024259\n",
      "\n",
      "Loading: USW00024283\n",
      "\n",
      "Loading: USW00024286\n",
      "\n",
      "Loading: USW00053119\n",
      "\n",
      "Loading: USW00053139\n",
      "\n",
      "Loading: USW00053150\n",
      "\n",
      "Loading: USW00093102\n",
      "\n",
      "Loading: USW00093104\n",
      "\n",
      "Loading: USW00093193\n",
      "\n",
      "Loading: USW00093205\n",
      "\n",
      "Loading: USW00093206\n",
      "\n",
      "Loading: USW00093209\n",
      "\n",
      "Loading: USW00093210\n",
      "\n",
      "Loading: USW00093225\n",
      "\n",
      "Loading: USW00093226\n",
      "\n",
      "Loading: USW00093227\n",
      "\n",
      "Loading: USW00093228\n",
      "\n",
      "Loading: USW00093230\n",
      "\n",
      "Loading: USW00093241\n",
      "\n",
      "Loading: USW00093242\n",
      "\n",
      "Loading: USW00093243\n",
      "\n",
      "Loading: USW00093245\n",
      "\n",
      "Loading: USW00094236\n",
      "\n",
      "Loading: USW00094299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read input station data\n",
    "inputStations = readInputStations(controlVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02c32d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if temperature and a gridded default slope file is specified, read it\n",
    "if (controlVars.variableEstimated=='tmax') & (len(controlVars.defaultTempLapse)!=0):     \n",
    "    tempDefaultLapse = Dataset(controlVars.defaultTempLapse)['tmaxLapse'][:]\n",
    "    #override user specified choice for the recomputeDefaultTempSlope option\n",
    "    parameters.recomputeDefaultTempSlope = 'false'\n",
    "elif (controlVars.variableEstimated=='tmin') & (len(controlVars.defaultTempLapse)!=0):\n",
    "    tempDefaultLapse = Dataset(controlVars.defaultTempLapse)['tminLapse'][:]\n",
    "    #override user specified choice for the recomputeDefaultTempSlope option\n",
    "    parameters.recomputeDefaultTempSlope = 'false'\n",
    "else: #else set the temp default lapse rate to spatially constant parameter value\n",
    "    tempDefaultLapse = np.ones((grid.nc,grid.nr))*parameters.defaultSlope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc775ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3, 1.3, 1.3, ..., 1.3, 1.3, 1.3],\n",
       "       [1.3, 1.3, 1.3, ..., 1.3, 1.3, 1.3],\n",
       "       [1.3, 1.3, 1.3, ..., 1.3, 1.3, 1.3],\n",
       "       ...,\n",
       "       [1.3, 1.3, 1.3, ..., 1.3, 1.3, 1.3],\n",
       "       [1.3, 1.3, 1.3, ..., 1.3, 1.3, 1.3],\n",
       "       [1.3, 1.3, 1.3, ..., 1.3, 1.3, 1.3]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempDefaultLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "034bd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if there are any invalid slopes in the default temperature\n",
    "#slope if used\n",
    "if len(controlVars.defaultTempLapse)!=0:\n",
    "    tempDefaultLapse[tempDefaultLapse < parameters.minSlope] = parameters.minSlope\n",
    "    tempDefaultLapse[(tempDefaultLapse > parameters.maxSlopeLower) & (grid.layerMask == 1)] = parameters.maxSlopeLower\n",
    "    tempDefaultLapse[(tempDefaultLapse > parameters.maxSlopeUpper) & (grid.layerMask == 2)] = parameters.maxSlopeUpper\n",
    "\n",
    "    #set metGrid default slope to QC'ed spatial lapse \n",
    "    metGrid.defaultSlope = tempDefaultLapse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a7400d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(metGrid.defaultSlope )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6d04e",
   "metadata": {},
   "source": [
    "# getNearStations:\n",
    "* **finds nearby stations for current grid point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearStations(staLat,staLon,staFacet,gridLat,gridLon,gridFacet,nMatch,maxDist):\n",
    "\n",
    "    \"\"\"\n",
    "     getNearStations finds nearby stations for current grid point\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input:   yPt, integer, y counter for current grid point\n",
    "               xPt, integer, x counter for current grid point\n",
    "               staLat, float, vector of station lat\n",
    "               staLon, float, vector of station lon\n",
    "               staFacet, integer, vector of station integer facets\n",
    "               grid, structure, structure containing grid\n",
    "               nMatch, integer, value of maximum number of stations to search for\n",
    "               maxDist, float, value of maximum radius to search for stations\n",
    "\n",
    "      Output:  nearStations, structure, structure containing indicies for stations\n",
    "               within search radius and those within that search\n",
    "               area on the same topographic facet as the current grid point\n",
    "\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    class structtype():\n",
    "        pass\n",
    "    \n",
    "    nearStations = structtype()\n",
    "    \n",
    "    \n",
    "    lat1, lon1 = gridLat, gridLon\n",
    "    lat2, lon2 = staLat, staLon\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    a = (np.sin(dlat / 2) * np.sin(dlat / 2) +\n",
    "         np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) *\n",
    "         np.sin(dlon / 2) * np.sin(dlon / 2))\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    staDist = radius * c\n",
    "    staAngles =360+ (np.arctan(dlon/dlat)*180/np.pi)\n",
    "\n",
    "\n",
    "    #get station indices from sorted distance (nearMatch)\n",
    "    distSort= np.argsort(staDist, axis=None)\n",
    "    nearMatch = distSort[0:int(nMatch)]\n",
    "\n",
    "    #find stations on same topographic facet as current grid point\n",
    "    staFacet= np.array(staFacet, dtype='float')\n",
    "    matchFacet = np.where(staFacet == gridFacet)\n",
    "    #get indicies of stations on same topographic facet\n",
    "    matchFacetSort= np.argsort(staDist[matchFacet], axis=None) \n",
    "\n",
    "\n",
    "    #take nMatch stations on same facet with consideration of distance\n",
    "    #from grid point\n",
    "    stationInds = np.array(matchFacet)[0,matchFacetSort[0:int(nMatch)]]\n",
    "    #now cull list based on distance from grid point\n",
    "    matchDist = staDist[stationInds] <= maxDist\n",
    "    #finalize station indices\n",
    "    facetStationInds = stationInds[matchDist]\n",
    "\n",
    "    #set output structure\n",
    "    nearStations.staDist = staDist\n",
    "    nearStations.staAngles = staAngles\n",
    "    nearStations.nearStationInds = nearMatch\n",
    "    nearStations.facetStationInds = facetStationInds\n",
    "       \n",
    "    \n",
    "    return nearStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9727df7",
   "metadata": {},
   "source": [
    "# calcCoastWeights:\n",
    "* **computes weights for stations as compared to the current grid point based on the differences in coastal distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa77a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCoastWeights(gridDistanceToCoast,stationDistanceToCoast,coastalExp):\n",
    "\n",
    "    \"\"\"\n",
    "     calcCoastWeights computes weights for stations as compared to the \n",
    "      current grid point based on the differences in coastal distance\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input: gridDistanceToCoast, float, distance to coast of current grid point\n",
    "       stationDistanceToCoast, float, distance to coast for nearby stations\n",
    "\n",
    "      Output:coastWeights, float, vector holding coastal weights for nearby stations\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #define a tiny float\n",
    "    tiny = 1e-5\n",
    "\n",
    "    #distance to coast weighting (e.g. Daly et al. 2002)\n",
    "    coastWeights = 1.0/((abs(gridDistanceToCoast-stationDistanceToCoast)+tiny)**(coastalExp))\n",
    "    #check for values > 1\n",
    "    coastWeights[coastWeights>1] = 1\n",
    "    #normalize weights\n",
    "    coastWeights = coastWeights/np.sum(coastWeights)\n",
    "    \n",
    "    return coastWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe957dc",
   "metadata": {},
   "source": [
    "# calcTopoPositionWeights:\n",
    "* **computes weights for nearby stations as compared to the current grid point based on the differences in topographic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69bcfd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTopoPositionWeights(gridTopoPosition,topoPosMinDiff,topoPosMaxDiff,topoPosExp,stationTopoPos):\n",
    "    \"\"\"\"\n",
    "    calcTopoPositionWeights computes weights for nearby stations as compared \n",
    "      to the current grid point based on the differences in topographic \n",
    "      position as in Daly et al. (2007), JAMC\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input:gridTopoPosition, float, distance to coast of current grid point\n",
    "       stationTopoPos, float, vector of topographic position of nearby stations\n",
    "       nearStationInds, integer, vector of nearby station indicies\n",
    "\n",
    "      Output: topoPositionWeights, float, vector holding topographic position weights\n",
    "                                   for nearby stations\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #initialize topographic position vector\n",
    "    topoPositionWeights = np.zeros([len(stationTopoPos),1])\n",
    "    #compute topographic position difference\n",
    "    topoDiff = abs(stationTopoPos-gridTopoPosition)\n",
    "\n",
    "    for i in range(0,len(stationTopoPos)):\n",
    "\n",
    "        #check if any differences are below min, set to 1 weight\n",
    "        if topoDiff[i]<=topoPosMinDiff:\n",
    "            topoPositionWeights[i] = 1\n",
    "        #if differences are in between max and min, compute using linear decay\n",
    "        elif topoDiff[i]>topoPosMinDiff:\n",
    "            topoPositionWeights[i]=1/((topoDiff[i]/topoPosMinDiff)**topoPosExp)\n",
    "        #if differences are larger than max, set to zero\n",
    "        elif topoDiff[i]>topoPosMaxDiff:\n",
    "            topoPositionWeights[i] = 0\n",
    "\n",
    "    topoPositionWeights = np.divide(topoPositionWeights,np.sum(topoPositionWeights))\n",
    "   \n",
    "    return topoPositionWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e6ee3",
   "metadata": {},
   "source": [
    "# calcLayerWeights:\n",
    "* *computes the weights of stations to the current grid point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6809f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcLayerWeights(gridLayer,gridElev,stationLayer,stationElev,layerExp):\n",
    "    \"\"\"\n",
    "    calcLayerWeights computes the weights of stations to the current grid point.  \n",
    "    Estimates a 2-layer atmosphere (inversion and free) based on topography.  \n",
    "    Helpful identifying inversion areas as defined in Daly et al. (2002, Climate Res.), section 7\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input: gridLayer, float, grid layer for current grid point\n",
    "               gridElev, float, grid elevation for current grid point\n",
    "               stationLayer, integer, layer of nearby stations\n",
    "               stationElev, float, elevation of nearby stations\n",
    "               layerExp, float, TIER parameter; exponent in weighting function\n",
    "\n",
    "      Output: layerWeights, float, vector holding layer weights for nearby stations\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #define a tiny float\n",
    "    tiny = 1e-6\n",
    "\n",
    "    #find nearby stations that match the grid layer\n",
    "    layerMatch=[]\n",
    "    for i in range(len(stationLayer)):\n",
    "        layerMatch.append(int(stationLayer[i])==gridLayer)\n",
    "        \n",
    "    #initalize weight variable\n",
    "    layerWeights = np.zeros([len(stationLayer),1]) \n",
    "    \n",
    "    \n",
    "    #set station weight in same layer to 1\n",
    "    layerWeights[layerMatch] = 1\n",
    "    #compute weights for stations in other layer, based on vertical distance difference\n",
    "    layerWeights[[not x for x in layerMatch]]= np.reshape(1/((abs(gridElev-np.array(stationElev)\\\n",
    "                                              [[not x for x in layerMatch]]+1)+tiny)**layerExp),(-1,1))\n",
    "    \n",
    "    #no station in other layer can have a weight >= 1.0\n",
    "    layerWeights[layerWeights>=1] = 0.99\n",
    "    #normalize weights\n",
    "    layerWeights = layerWeights/np.sum(layerWeights)\n",
    "    \n",
    "    return layerWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75fd52",
   "metadata": {},
   "source": [
    "# calcSymapWeights:\n",
    "* *computes weights for nearby stations following the concept of the SYMAP algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b03d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSymapWeights(staDist,staAngles,distanceWeightScale,distanceWeightExp,maxDist):\n",
    "    \"\"\"\n",
    "     calcSymapWeights computes weights for nearby stations following the\n",
    "      concept of the SYMAP algorithm (Shepard 1984).  Uses Barnes (1964) type\n",
    "      distance weights instead of the exact SYMAP method.  Angular weighting\n",
    "      is from Shepard (1984).\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input: staDist, float, vector of station distances to current grid point\n",
    "       staAngles, float, vector of station angles from current grid point\n",
    "       distanceWeightScale, float, input TIER parameter\n",
    "       maxDist, float, input TIER parameter of maximum search distance\n",
    "\n",
    "      Output: symapWeights,float, vector holding SYMAP weights of nearby stations\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #set number of stations\n",
    "    nMatch = len(staDist)\n",
    "\n",
    "    #to radians\n",
    "    toRad = np.pi/180.0\n",
    "\n",
    "    #compute mean from nearest N stations using Barnes (1964) type distance weights\n",
    "    #Set the scale factor to depends on mean distance of nearby stations\n",
    "    if len(staDist):\n",
    "        meanDist = mean(staDist)\n",
    "        scale = distanceWeightScale*(meanDist/(maxDist));\n",
    "\n",
    "        #compute initial distance weights\n",
    "        distanceWeights = np.exp(-((staDist**distanceWeightExp)/scale))\n",
    "\n",
    "        #directional isolation (Shepard 1984)\n",
    "        #set angular isolation weight variable\n",
    "        angleWeight = np.zeros([int(nMatch),1])\n",
    "        #run through stations compute angle and isolation from other stations\n",
    "        angleWeight=[]\n",
    "        for i in range(0,nMatch):\n",
    "            cosThetaSta = np.zeros([int(nMatch),1])\n",
    "            cosThetaSta=[]\n",
    "            for j in range(0,nMatch):\n",
    "                #angle of station in radians from next station\n",
    "                cosThetaSta.append(np.cos((staAngles[i]-staAngles[j])*toRad))\n",
    "\n",
    "            #total angular isolation weight        \n",
    "            angleWeight.append(np.sum(distanceWeights[i]*(1-np.array(cosThetaSta))))\n",
    "\n",
    "\n",
    "        #increment integer vector: 1 to nMatch \n",
    "        inds = range(0,nMatch)\n",
    "        angleWeight=np.array(angleWeight)\n",
    "        \n",
    "        # Supress/hide the warning\n",
    "        np.seterr(invalid='ignore')\n",
    "\n",
    "        #compute weights as a combination of distance and directional isolation\n",
    "        symapWeights = np.multiply(distanceWeights**2,1+(angleWeight/np.sum(angleWeight[np.setxor1d(inds,i)])))\n",
    "        #normalize weights\n",
    "        symapWeights = symapWeights/np.sum(symapWeights)\n",
    "    else:\n",
    "\n",
    "        symapWeights= np.zeros([1,int(nMatch)]) \n",
    "\n",
    "    \n",
    "    return symapWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125593a6",
   "metadata": {},
   "source": [
    "# calcFinalWeights:\n",
    "* *computes the weights of stations to the current grid point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "138fbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFinalWeights(varEstimated,symapWeights,coastWeights,topoPositionWeights,layerWeights):\n",
    "    \"\"\"\n",
    "     calcLayerWeights computes the weights of stations to the current grid\n",
    "      point.  Estimates a 2-layer atmosphere (inversion and free) based on\n",
    "      topography.  Helpful identifying inversion areas as defined in \n",
    "      Daly et al. (2002, Climate Res.), section 7\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input: varEstimated, string, met variable being estimated\n",
    "       symapWeights, float, vector of SYMAP weights\n",
    "       coastWeights, float, vector of distance to coast weights\n",
    "       topoPositionWeights, float, vector of topographic position weights\n",
    "       layerWeights, float, vector of inversion layer weights\n",
    "\n",
    "      Output: finalWeights, float, vector holding final weights for nearby stations\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #inversion layer and topographic position weighting (layerWeights \n",
    "    #and topoPosition) not used for precipitation\n",
    "    if varEstimated=='precip':\n",
    "        finalWeights = symapWeights*coastWeights\n",
    "    elif (varEstimated=='tmax') or (varEstimated=='tmin'):\n",
    "        finalWeights = symapWeights*coastWeights*topoPositionWeights*layerWeights\n",
    "    else:\n",
    "        print('error:Unrecognized variable: %s'%varEstimated)\n",
    "    \n",
    "    #normalize final weights\n",
    "    finalWeights = finalWeights/np.sum(finalWeights)\n",
    "\n",
    "    #prevent badly conditioned weight matrices in the regression set minium weight to a small \n",
    "    #number that is still large enough for numerics to compute\n",
    "    finalWeights[finalWeights<1e-6] = 1e-6\n",
    "    finalWeights[finalWeights==np.nan] = 1e-6 ####MAF:aded this shoild check later with andy\n",
    "    \n",
    "    return finalWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7139bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######there is (x,y) that facetStationInds=[]########\n",
    "\n",
    "\n",
    "# staLat= inputStations.meta.lat\n",
    "# staLon= inputStations.meta.lon\n",
    "# staFacet= inputStations.meta.facet\n",
    "# gridLat=grid.lat[131,9]\n",
    "# gridLon=grid.lon[131,9]\n",
    "# gridFacet=grid.facet[131,9]\n",
    "# nMatch=parameters.nMaxNear\n",
    "# maxDist=parameters.maxDist\n",
    "\n",
    "\n",
    "# lat1, lon1 = gridLat, gridLon\n",
    "# lat2, lon2 = staLat, staLon\n",
    "# radius = 6371  # km\n",
    "\n",
    "# dlat = np.radians(lat2 - lat1)\n",
    "# dlon = np.radians(lon2 - lon1)\n",
    "# a = (np.sin(dlat / 2) * np.sin(dlat / 2) +\n",
    "#      np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) *\n",
    "#      np.sin(dlon / 2) * np.sin(dlon / 2))\n",
    "# c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "# staDist = radius * c\n",
    "# staAngles =np.arctan(dlon/dlat) * 180 / np.pi\n",
    "\n",
    "\n",
    "# #get station indices from sorted distance (nearMatch)\n",
    "# distSort= np.argsort(staDist, axis=None)\n",
    "# nearMatch = distSort[0:int(nMatch)]\n",
    "\n",
    "# #find stations on same topographic facet as current grid point\n",
    "# staFacet= np.array(staFacet, dtype='float')\n",
    "# matchFacet = np.where(staFacet == gridFacet)\n",
    "# #get indicies of stations on same topographic facet\n",
    "# matchFacetSort= np.argsort(staDist[matchFacet], axis=None) \n",
    "\n",
    "\n",
    "# #take nMatch stations on same facet with consideration of distance\n",
    "# #from grid point\n",
    "# stationInds = np.array(matchFacet)[0,matchFacetSort[0:int(nMatch)]]\n",
    "# #now cull list based on distance from grid point\n",
    "# matchDist = staDist[stationInds] <= maxDist\n",
    "# #finalize station indices\n",
    "# facetStationInds = stationInds[matchDist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff15947",
   "metadata": {},
   "source": [
    "# calcWeightedRegression:\n",
    "* *computes a weighted linear regression of station data against elevationn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0038c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWeightedRegression(stationElev,stationVar,stationWeights):\n",
    "    \"\"\"\n",
    "\n",
    "     calcWeightedRegression computes a weighted linear regression of station\n",
    "      data against elevation.  Weight vector determines weight of each station\n",
    "      in the regression.  Here they are computed as the combination of the\n",
    "      component geophysical weights (e.g. coastal, layer, SYMAP).  Following\n",
    "      Daly et al. (1994,2002)\n",
    "    \n",
    "     Arguments:\n",
    "    \n",
    "      Input:\n",
    "    \n",
    "      stationElev, float, vector of elevation of nearby stations\n",
    "       stationDist, float, vector of distance to nearby stations\n",
    "       stationVar, float, vector containing meteorological variable values from\n",
    "                      stations\n",
    "       stationWeights, float,vector of station weights\n",
    "    \n",
    "      Output:\n",
    "       \n",
    "       linearFit, float, vector holding the two coefficients of the weighted\n",
    "                         linear regression\n",
    "    \n",
    "     Author: Andrew Newman, NCAR/RAL\n",
    "     Email : anewman@ucar.edu\n",
    "     Postal address:\n",
    "         P.O. Box 3000\n",
    "         Boulder,CO 80307\n",
    "    \n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "    \n",
    "    This file is part of TIER.\n",
    "    \n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "    \n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "    \n",
    "     You should have received a copy of the GNU General Public License\n",
    "    along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #create weighted linear regression matricies\n",
    "    n = len(stationElev)\n",
    "    X = np.c_[np.ones(len(stationElev)), stationElev]\n",
    "    W = np.eye(n,n)\n",
    "    W[W==1] = stationWeights\n",
    "    xw=X.T@W\n",
    "\n",
    "    #compute weighted linear regression\n",
    "    linearFit=(np.linalg.pinv(xw @ X) @ xw @ stationVar).T\n",
    "\n",
    "    #change order of coefficients for convenience\n",
    "    linearFit=np.roll(linearFit,-1)[0]\n",
    "\n",
    "                 \n",
    "    return linearFit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb74dd8",
   "metadata": {},
   "source": [
    "# calcPrecip:\n",
    "* *computes the first pass TIER estimate of precipitation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efb3eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPrecip(parameters,gridElev,defaultSlope,finalWeightsNear,finalWeightsFacet,symapWeights,\\\n",
    "               stationElevNear,stationElevFacet,stationVarNear,stationVarFacet):\n",
    "    \n",
    "    \"\"\"\n",
    "     calcPrcp computes the first pass TIER estimate of precipitation\n",
    "\n",
    "     Summary: This algorithm generally follows Daly et al. (1994,2002,2007,2008) and\n",
    "     others.  However, here the regression estimated parameters\n",
    "     and the grid point elevation to compute the precipitation is not done.\n",
    "     Instead, the baseInterp estimate is used at all grid points as the intercept\n",
    "     and the weighted linear regression slope is used to adjust the baseInterp\n",
    "     estimate up or down based on the elevation difference between the grid\n",
    "     and the baseInterp weighted station elevation.  This approach gives similar\n",
    "     results and is effectively an elevation adjustment to a baseInterp estimate\n",
    "     where the baseInterp weights here are computed using all knowledge based\n",
    "     terms in addition to the SYMAP distance & angular isolation weights\n",
    "     Other modifications from the above cited papers are present and\n",
    "     summarized below.\n",
    "\n",
    "\n",
    "     Specific modifications/notes for initial precipitation implementation \n",
    "     (eq. 2, Daly et al. 2002):\n",
    "     1) Here there are only 4-directional facets and flat (see tierPreprocessing.m for details)\n",
    "        1 = N\n",
    "        2 = E\n",
    "        3 = S\n",
    "        4 = W\n",
    "        5 = Flat\n",
    "     2) no elevation weighting factor\n",
    "     3) cluster weighting factor using symap type weighting\n",
    "     4) no topographic facet weighting factor\n",
    "\n",
    "     5) number of stations and facet weighting:\n",
    "     the nMaxNear nearest stations are always used to determine the base\n",
    "     precip value, then only stations on the correct facet are\n",
    "     used to determine the elevation-variable relationship (slope).  \n",
    "     facet weighting where stations on same facet but with other facets \n",
    "     inbetween get less weight is not considered.  All stations on the same \n",
    "     facet get the same \"facet\" weight\n",
    "     6) default lapse rates are updated after first pass to remove the\n",
    "     spatially constant default lapse rate constraint (updatePrecipSlope.m)\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input:\n",
    "\n",
    "       parameters  , structure, structure holding all TIER parameters\n",
    "       gridElev    , float    , elevation of current grid point\n",
    "       defaultSlope, float    , default normalized precipitation slope at\n",
    "                                current grid point as current grid point\n",
    "       finalWeights,       float, station weights for nearby stations\n",
    "       finalWeightsFacet, float, station weights for nearby stations on same\n",
    "                                  slope facet\n",
    "       symapWeights,      float , symap station weights for nearby stations\n",
    "       stationElevNear,   float , station elevations for nearby stations\n",
    "       stationElevFacet, float , station elevations for nearby stations on\n",
    "                                  same slope facet as current grid point\n",
    "       stationVarNear   , float , station values for nearby stations\n",
    "       stationVarFacet , float , sataion values for nearby stations on same \n",
    "                                  slope facet as current grid point\n",
    "\n",
    "      Output:\n",
    "\n",
    "       metPoint, structure, structure housing all grids related to\n",
    "                            precipitation for the current grid point\n",
    "\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #define tiny\n",
    "    tiny = 1e-15\n",
    "    #define large;\n",
    "    large = 1e15\n",
    "\n",
    "    #set local min station parameter\n",
    "    nMinNear = parameters.nMinNear\n",
    "\n",
    "    #local slope values\n",
    "    minSlope = parameters.minSlope\n",
    "    maxSlope = parameters.maxInitialSlope\n",
    "\n",
    "    #initalize metPoint structure\n",
    "    metPoint.rawField             = np.nan\n",
    "    metPoint.intercept            = np.nan\n",
    "    metPoint.slope                = np.nan\n",
    "    metPoint.normSlope            = np.nan\n",
    "    metPoint.baseInterpField      = np.nan\n",
    "    metPoint.baseInterpElev       = np.nan\n",
    "    metPoint.baseInterpUncert     = np.nan\n",
    "    metPoint.slopeUncert          = np.nan\n",
    "    metPoint.normSlopeUncert      = np.nan\n",
    "    metPoint.intercept            = np.nan\n",
    "    metPoint.validRegress         = np.nan\n",
    "\n",
    "    #first estimate the 'baseInterp' value at grid point, but use full knowledge based weights if possible. \n",
    "    #this serves as the base estimate with no weighted linear elevation regression\n",
    "\n",
    "    #if the final weight vector is invalid, default to symap weights only\n",
    "    if np.isnan(finalWeightsNear[0]):\n",
    "        #compute baseInterp precipitaiton\n",
    "        metPoint.baseInterpField = np.sum([a*b for a,b in zip(symapWeights,stationVarNear)])/np.sum(symapWeights)\n",
    "        #compute mean elevation of baseInterp stations\n",
    "        metPoint.baseInterpElev = np.sum([a*b for a,b in zip(symapWeights,stationElevNear)])/np.sum(symapWeights)\n",
    "        #estimate uncertainty using standard deviation of leave-one-out estimates\n",
    "        nsta = len(symapWeights)\n",
    "        combs = np.array(list(combinations(range(0, nsta), nsta-1)))\n",
    "\n",
    "        symcombs=[symapWeights[combs[i,:]] for i in range(len(symapWeights))]\n",
    "        varnearcombs= [stationVarNear[combs[i,:]][:,0] for i in range(len(stationVarNear))]\n",
    "        metPoint.baseInterpUncert = np.std(np.sum([a*b for a,b in zip(symcombs,varnearcombs)], axis=1)/np.sum(symcombs, axis=1))\n",
    "    else: #estimate simple average using final weights\n",
    "        metPoint.baseInterpField = np.sum([a*b for a,b in zip(finalWeightsNear,stationVarNear)])/np.sum(finalWeightsNear)   \n",
    "        metPoint.baseInterpElev = np.sum([a*b for a,b in zip(finalWeightsNear,stationElevNear)])/np.sum(finalWeightsNear)\n",
    "        #estimate uncertainty using standard deviation of leave-one-out\n",
    "        #estimates\n",
    "        nsta = len(finalWeightsNear)\n",
    "        combs = np.array(list(combinations(range(0, nsta), nsta-1)))\n",
    "\n",
    "        finalcombs=[finalWeightsNear[combs[i,:]] for i in range(len(finalWeightsNear))]\n",
    "        varnearcombs= [stationVarNear[combs[i,:]][:,0] for i in range(len(stationVarNear))]       \n",
    "        metPoint.baseInterpUncert = np.std(np.sum([a*b for a,b in zip(finalcombs,varnearcombs)],axis=1)/np.sum(finalcombs,axis=1))\n",
    "\n",
    "    #if there are more than nMinNear stations, proceed with weighted elevation regression\n",
    "    if len(stationElevFacet) >= nMinNear:\n",
    "        #create weighted linear regression relationship\n",
    "        linFit = calcWeightedRegression(stationElevFacet,stationVarFacet,finalWeightsFacet);\n",
    "        #define normalized slope estimate\n",
    "        elevSlope = linFit[0]/np.mean(stationVarFacet)\n",
    "\n",
    "        #Run through station combinations and find outliers to see if we can get a valid met var - elevation slope\n",
    "        if (elevSlope < minSlope) or (elevSlope > maxSlope):\n",
    "            #number of stations considered on current grid point facet\n",
    "            nSta = len(stationVarFacet)\n",
    "            #variable to track slope changes when estimating slope in weighted regression\n",
    "            maxSlopeDelta = 0\n",
    "\n",
    "            #set combinations for the number of combinations possbile selecting nSta-1 stations given nSta stations\n",
    "            combs = np.array(list(combinations(range(0, nSta), nSta-1)))\n",
    "            #counter to track number of valid slopes\n",
    "            cnt = 1\n",
    "            #initalize variable to hold valid slopes\n",
    "            combSlp = []\n",
    "            #step through combinations\n",
    "            for c in range(len(combs[:,0])):\n",
    "                #define station attributes matrix (X) for regression \n",
    "                X = np.c_[np.ones(len(np.array(stationElevFacet)[combs[c,:]])), np.array(stationElevFacet)[combs[c,:]]]\n",
    "\n",
    "                #if X is square\n",
    "                if np.shape(X)[0]==np.shape(X)[1]:\n",
    "                    #if well conditioned\n",
    "                    if (np.linalg.cond(X))**-1 >tiny:\n",
    "                        #compute weighted regression\n",
    "                        tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                        #set normalized slope variable\n",
    "                        elevSlopeTest = tmpLinFit[0]/np.mean(np.array(stationVarFacet)[combs[c]])\n",
    "                        #compute change in slope from initial estimate\n",
    "                        slopeDelta = abs(elevSlope - elevSlopeTest)\n",
    "                    else: #if X not well conditioned, set to unrealistic values\n",
    "                        elevSlopeTest = large\n",
    "                        slopeDelta = -large\n",
    "\n",
    "                else:\n",
    "                    #compute weighted regression\n",
    "                    tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                    #set normalized slope variable\n",
    "                    elevSlopeTest = tmpLinFit[0]/np.mean(np.array(stationVarFacet)[combs[c]])\n",
    "                    #compute change in slope from initial estimate\n",
    "                    slopeDelta = abs(elevSlope - elevSlopeTest)\n",
    "\n",
    "\n",
    "                #if the recomputed slope is valid and has the largest slope\n",
    "                #change, this specific case is the best estimate removing\n",
    "                #the largest outlier in terms of estimated slope\n",
    "                if (elevSlopeTest > minSlope) and (elevSlopeTest < maxSlope) and (slopeDelta > maxSlopeDelta):\n",
    "                    removeOutlierInds = combs[c]\n",
    "                    maxSlopeDelta = slopeDelta\n",
    "                    #add valid slope to vector\n",
    "                    combSlp.append(elevSlopeTest)\n",
    "                    #increment counter\n",
    "                    cnt = cnt + 1\n",
    "                #catch the rest of the recomputed slopes that are valid\n",
    "                elif (elevSlopeTest > minSlope) and (elevSlopeTest < maxSlope):\n",
    "                    #add valid slope to vector\n",
    "                    combSlp.append(elevSlopeTest)\n",
    "                    #increment counter\n",
    "                    cnt = cnt + 1\n",
    "\n",
    "\n",
    "            #if two or more valid combination of stations estimate uncertainty of slope at grid point using standard\n",
    "            #deviation of estimates\n",
    "            if (cnt-1) >= 2:\n",
    "                metPoint.normSlopeUncert = np.std(combSlp)               \n",
    "\n",
    "            #if there was a valid outlier removal combination, use the 'best' combination\n",
    "            if maxSlopeDelta>0:\n",
    "                #compute regression estimate\n",
    "                linFit = calcWeightedRegression(np.array(stationElevFacet)[removeOutlierInds],\\\n",
    "                                                np.array(stationVarFacet[removeOutlierInds]),\\\n",
    "                                                np.array(finalWeightsFacet[removeOutlierInds]))\n",
    "\n",
    "                #override the regression intercept with the baseInterp estimate\n",
    "                linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "                if np.isnan(linFit[0]):\n",
    "                    linFit[0] = defaultSlope*metPoint.baseInterpField\n",
    "                    tmpField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "                else:\n",
    "                    tmpField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "\n",
    "                metPoint.rawField = tmpField\n",
    "                metPoint.slope = linFit[0]\n",
    "                metPoint.normSlope = linFit[0]/np.mean(stationVarFacet[removeOutlierInds])\n",
    "                metPoint.intercept = linFit[1]\n",
    "                metPoint.validRegress = 1\n",
    "            else:\n",
    "                linFit=np.zeros([2,1])\n",
    "                linFit[0] = defaultSlope*metPoint.baseInterpField\n",
    "                linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "                metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "                metPoint.normSlope  = linFit[0]/np.mean(stationVarFacet)\n",
    "                metPoint.slope      = linFit[0]\n",
    "                metPoint.intercept  = linFit[1]\n",
    "\n",
    "        #if regression coefficients are invalid\n",
    "        elif np.isnan(linFit[0]):\n",
    "            linFit=np.zeros([2,1])\n",
    "            linFit[0] = defaultSlope*metPoint.baseInterpField\n",
    "            linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "            metPoint.rawField  = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "            metPoint.slope     = linFit[0]\n",
    "            metPoint.normSlope = linFit[0]\n",
    "            metPoint.intercept = linFit[1]\n",
    "        else:\n",
    "\n",
    "            linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "            metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "            metPoint.slope     = linFit[0]\n",
    "            metPoint.intercept = linFit[1]\n",
    "            metPoint.normSlope = linFit[0]/np.mean(stationVarFacet)\n",
    "            metPoint.validRegress = 1\n",
    "\n",
    "            #run through station combinations to estimate uncertainty in\n",
    "            #slope estimate\n",
    "            nSta = len(stationVarFacet)\n",
    "            combs = np.array(list(combinations(range(0, nSta), nSta-1)))\n",
    "            cnt = 1\n",
    "\n",
    "\n",
    "            combSlp = []\n",
    "            #step through combinations\n",
    "            for c in range(len(combs[:,0])):\n",
    "                X = np.c_[np.ones(len(np.array(stationElevFacet)[combs[c,:]])), np.array(stationElevFacet)[combs[c,:]]]          \n",
    "\n",
    "                #if X is square\n",
    "                if np.shape(X)[0]==np.shape(X)[1]: \n",
    "                    #if X is well conditioned\n",
    "                    if (np.linalg.cond(X))**-1 >tiny:\n",
    "                        tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                        elevSlopeTest = tmpLinFit[0]/np.mean(np.array(stationVarFacet)[combs[c]])\n",
    "                    else: #if not well conditioned, set variables to unrealistic values\n",
    "                        elevSlopeTest = large\n",
    "\n",
    "                else:\n",
    "                    tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                    elevSlopeTest = tmpLinFit[0]/np.mean(np.array(stationVarFacet)[combs[c]])\n",
    "\n",
    "\n",
    "                if (elevSlopeTest > minSlope) and (elevSlopeTest < maxSlope):\n",
    "                    combSlp.append(elevSlopeTest)\n",
    "                    cnt = cnt + 1\n",
    "\n",
    "\n",
    "\n",
    "            #if two or more valid combination of stations estimate uncertainty of slope at grid point using standard\n",
    "            #deviation of estimates\n",
    "            if cnt-1 >= 2:\n",
    "                metPoint.normSlopeUncert = np.std(combSlp)\n",
    "\n",
    "\n",
    "    #only one station within range on Facet - revert to nearest with default slope\n",
    "    elif len(stationVarFacet) == 1: \n",
    "        linFit=np.zeros([2,1])\n",
    "        linFit[0] = defaultSlope*metPoint.baseInterpField\n",
    "        linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "        metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "        metPoint.slope     = linFit[0]\n",
    "        metPoint.intercept = linFit[1]\n",
    "        metPoint.normSlope = linFit[0]/metPoint.baseInterpField\n",
    "    #less than nMinNear stations within range - attempt regression anyway\n",
    "    elif (len(stationVarFacet) < nMinNear) and (len(stationVarFacet)):\n",
    "\n",
    "        linFit = calcWeightedRegression(stationElevFacet,stationVarFacet,finalWeightsFacet)\n",
    "\n",
    "        elevSlope = linFit[0]/np.mean(stationVarFacet)\n",
    "\n",
    "        if (elevSlope < minSlope) or (elevSlope > maxSlope) or (np.isnan(elevSlope)):\n",
    "            linFit[0] = defaultSlope*metPoint.baseInterpField\n",
    "            linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "            metPoint.normSlope = linFit[0]/metPoint.baseInterpField\n",
    "            metPoint.slope     = linFit[0]\n",
    "            metPoint.intercept = linFit[1]\n",
    "        else:\n",
    "\n",
    "            metPoint.intercept = metPoint.baseInterpField\n",
    "            metPoint.slope = linFit[0]\n",
    "            metPoint.normSlope = linFit[0]/metPoint.baseInterpField\n",
    "\n",
    "\n",
    "        #override intercept\n",
    "        linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "        metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "\n",
    "    else: #no original stations in distance search...\n",
    "        linFit=np.zeros([2,1])\n",
    "        linFit[0] = defaultSlope*metPoint.baseInterpField\n",
    "        linFit[1] = metPoint.baseInterpField\n",
    "\n",
    "        metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "        metPoint.slope     = linFit[0]\n",
    "        metPoint.intercept = linFit[1]\n",
    "        metPoint.normSlope = linFit[1]/metPoint.baseInterpField\n",
    "\n",
    "    \n",
    "    return metPoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71591f9",
   "metadata": {},
   "source": [
    "# calcTemp:\n",
    "* *computes the first pass TIER estimate of varEstimated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a77eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTemp(parameters,gridElev,defaultSlope,gridLayer,finalWeightsNear,finalWeightsFacet,symapWeights,\\\n",
    "             stationElevNear,stationElevFacet,stationVarNear,stationVarFacet):\n",
    "    \"\"\"\n",
    "    Summary: This algorithm generally follows Daly et al. (1994,2002,2007,2008) and\n",
    "     others.  However, here the regression estimated parameters\n",
    "     and the grid point elevation to compute the precipitation is not done.\n",
    "     Instead, the baseInterp estimate is used at all grid points as the intercept\n",
    "     and the weighted linear regression slope is used to adjust the baseInterp\n",
    "     estimate up or down based on the elevation difference between the grid\n",
    "     and the baseInterp weighted station elevation.  This approach gives similar\n",
    "     results and is effectively an elevation adjustment to a baseInterp estimate\n",
    "     where the baseInterp weights here are computed using all knowledge based\n",
    "     terms in addition to the SYMAP distance & angular isolation weights\n",
    "     Other modifications from the above cited papers are present and\n",
    "     summarized below.\n",
    "\n",
    "\n",
    "     Specific modifications/notes for initial temperature implementation \n",
    "     (eq. 2, Daly et al. 2002):\n",
    "     1) Here there are only 4-directional facets and flat (see tierPreprocessing.m for details)\n",
    "        1 = N\n",
    "        2 = E\n",
    "        3 = S\n",
    "        4 = W\n",
    "        5 = Flat\n",
    "     2) no elevation weighting factor\n",
    "     3) cluster weighting factor using symap type weighting\n",
    "     4) no topographic facet weighting factor\n",
    "\n",
    "     5) number of stations and facet weighting:\n",
    "     the nMaxNear nearest stations are always used to determine the base\n",
    "     temperature value, then only stations on the correct facet are\n",
    "     used to determine the elevation-variable relationship (slope).  \n",
    "     facet weighting where stations on same facet but with other facets \n",
    "     inbetween get less weight is not considered.  All stations on the same \n",
    "     facet get the same \"facet\" weight\n",
    "     6) default lapse rates can be determined from available sounding data that\n",
    "     has been interpolated to the DEM\n",
    "     7) used a search radius of 20-km for layer-1 or 2 determination for temp\n",
    "     inversions (see tierPreprocessing.m for details)\n",
    "     8) The coastal proximity weighting of Daly et al. (2003) is not\n",
    "     implemented\n",
    "     9) default lapse rates are updated after first pass to remove the\n",
    "     spatially constant default lapse rate constraint (updateTempSlope.m)\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input:\n",
    "\n",
    "       parameters  , structure, structure holding all TIER parameters\n",
    "       gridElev    , float    , elevation of current grid point\n",
    "       defaultSlope, float    , default slope for current grid point\n",
    "       gridLayer   , float    , grid point layer in conceptual two-layer\n",
    "                                atmosphere (Daly et al. 2002)\n",
    "       finalWeights,       float, station weights for nearby stations\n",
    "       finalWeightsFacet, float, station weights for nearby stations on same\n",
    "                                  slope Facet\n",
    "       symapWeights,      float , symap station weights for nearby stations\n",
    "       stationElevNear,   float , station elevations for nearby stations\n",
    "       stationElevFacet, float , station elevations for nearby stations on\n",
    "                                  same slope Facet as current grid point\n",
    "       stationVarNear   , float , station values for nearby stations\n",
    "       stationVarFacet , float , sataion values for nearby stations on same \n",
    "                                  slope Facet as current grid point\n",
    "\n",
    "      Output:\n",
    "\n",
    "       metPoint, structure, structure housing all grids related to\n",
    "                            precipitation for the current grid point\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #define tiny\n",
    "    tiny = 1e-15\n",
    "    #define large;\n",
    "    large = 1e15\n",
    "    \n",
    "    #set local min station parameter\n",
    "    nMinNear = parameters.nMinNear\n",
    "    \n",
    "    #local slope values\n",
    "    minSlope = parameters.minSlope\n",
    "    maxSlopeLower = parameters.maxSlopeLower\n",
    "    maxSlopeUpper = parameters.maxSlopeUpper\n",
    "\n",
    "    \n",
    "    #initalize metPoint structure\n",
    "    metPoint.rawField             = np.nan\n",
    "    metPoint.intercept            = np.nan\n",
    "    metPoint.slope                = np.nan\n",
    "    metPoint.baseInterpField      = np.nan\n",
    "    metPoint.baseInterpElev       = np.nan\n",
    "    metPoint.baseInterpUncert     = np.nan\n",
    "    metPoint.slopeUncert          = np.nan\n",
    "    metPoint.intercept            = np.nan\n",
    "    metPoint.validRegress         = np.nan\n",
    "    \n",
    "    #first estimate the 'baseInterp' value at grid point, but use full knowledge\n",
    "    #based weights if possible. this serves as the base estimate with no \n",
    "    #weighted linear elevation regression\n",
    "\n",
    "\n",
    "    #if the final weight vector is invalid, default to symap weights only\n",
    "    if np.isnan(finalWeightsNear[0]):\n",
    "        #compute baseInterp precipitaiton\n",
    "        metPoint.baseInterpField = np.sum([a*b for a,b in zip(symapWeights,stationVarNear)])/np.sum(symapWeights)\n",
    "        #compute mean elevation of baseInterp stations\n",
    "        metPoint.baseInterpElev = np.sum([a*b for a,b in zip(symapWeights,stationElevNear)])/np.sum(symapWeights)\n",
    "        #estimate uncertainty using standard deviation of leave-one-out estimates\n",
    "        nsta = len(symapWeights)\n",
    "        combs = np.array(list(combinations(range(0, nsta), nsta-1)))\n",
    "                \n",
    "        symcombs=[symapWeights[combs[i,:]] for i in range(len(symapWeights))]\n",
    "        varnearcombs= [stationVarNear[combs[i,:]][:,0] for i in range(len(stationVarNear))]\n",
    "        metPoint.baseInterpUncert = np.std(np.sum([a*b for a,b in zip(symcombs,varnearcombs)],\\\n",
    "                                                  axis=1)/np.sum(symcombs, axis=1))\n",
    "\n",
    "    else: #estimate simple average using final weights\n",
    "        metPoint.baseInterpField = np.sum([a*b for a,b in zip(finalWeightsNear,stationVarNear)])/np.sum(finalWeightsNear) \n",
    "        metPoint.baseInterpElev = np.sum([a*b for a,b in zip(finalWeightsNear,stationElevNear)])/np.sum(finalWeightsNear)\n",
    "        #estimate uncertainty using standard deviation of leave-one-out estimates\n",
    "        nsta = len(finalWeightsNear)\n",
    "        combs = np.array(list(combinations(range(0, nsta), nsta-1)))\n",
    "\n",
    "        finalcombs=[finalWeightsNear[combs[i,:]] for i in range(len(finalWeightsNear))]\n",
    "        varnearcombs= [stationVarNear[combs[i,:]][:,0] for i in range(len(stationVarNear))]       \n",
    "        metPoint.baseInterpUncert = np.std(np.sum([a*b for a,b in zip(finalcombs,varnearcombs)],axis=1)/np.sum(finalcombs,axis=1))\n",
    "\n",
    "\n",
    "\n",
    "    #if there are more than nMinNear stations, proceed with weighted elevation regression\n",
    "    if len(stationElevFacet) >= nMinNear:\n",
    "        #create weighted linear regression relationship\n",
    "        linFit = calcWeightedRegression(stationElevFacet,stationVarFacet,finalWeightsFacet)\n",
    "\n",
    "        #Run through station combinations and find outliers to see if we can get a valid met var - elevation slope\n",
    "        #make comparisons for valid slope temperature has bounds for each layer\n",
    "        elevSlope = linFit[0]\n",
    "        if (elevSlope < minSlope) or (elevSlope > maxSlopeLower and gridLayer==1) or\\\n",
    "                (elevSlope>maxSlopeUpper and gridLayer==2):\n",
    "                \n",
    "            #number of stations considered on current grid point facet\n",
    "            nSta = len(stationVarFacet)\n",
    "            #variable to track slope changes when estimating slope in weighted regression\n",
    "            maxSlopeDelta = 0\n",
    "                \n",
    "            for i in nSta-1:\n",
    "                combs = np.array(list(combinations(range(0, nSta), i)))\n",
    "                cnt = 1\n",
    "                combSlp = []\n",
    "                for c in range(len(combs[:,0])):\n",
    "                    X = np.c_[np.ones(len(np.array(stationElevFacet)[combs[c,:]])), np.array(stationElevFacet)[combs[c,:]]]\n",
    "\n",
    "                    #if X is square\n",
    "                    if np.shape(X)[0]==np.shape(X)[1]:\n",
    "                        #if X is well conditioned\n",
    "                        if (np.linalg.cond(X))**-1 >tiny:\n",
    "                            tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                            elevSlopeTest = tmpLinFit[0]\n",
    "                            slopeDelta = abs(elevSlope - elevSlopeTest)\n",
    "                        else: #if X not well conditioned, set to unrealistic values\n",
    "                            elevSlopeTest = large\n",
    "                            slopeDelta = -large\n",
    "                        \n",
    "                    else:\n",
    "                        tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                        elevSlopeTest = tmpLinFit[0]\n",
    "                        slopeDelta = abs(elevSlope - elevSlopeTest)\n",
    "                    \n",
    "\n",
    "                    if elevSlopeTest > minSlope and slopeDelta > maxSlopeDelta:\n",
    "                        if (elevSlopeTest < maxSlopeLower and gridLayer == 1) or\\\n",
    "                            (elevSlopeTest < maxSlopeUpper and gridLayer == 2):\n",
    "                \n",
    "                            removeOutlierInds = combs[c]\n",
    "                            maxSlopeDelta = slopeDelta\n",
    "                            combSlp.append(elevSlopeTest) \n",
    "                            cnt = cnt + 1\n",
    "                        \n",
    "                    elif elevSlopeTest > minSlope:\n",
    "                        if (elevSlopeTest < maxSlopeLower and gridLayer == 1) or \\\n",
    "                            (elevSlopeTest < maxSlopeUpper and gridLayer == 2):\n",
    "                            combSlp.append(elevSlopeTest)\n",
    "                            cnt = cnt + 1\n",
    "                                        \n",
    "                #if two or more valid combination of stations estimate uncertainty of slope at grid point using standard\n",
    "                #deviation of estimates\n",
    "                if (cnt-1) >= 2:\n",
    "                    metPoint.slopeUncert = np.std(combSlp)\n",
    "                \n",
    "            \n",
    "            \n",
    "            if maxSlopeDelta>0:\n",
    "                linFit = calcWeightedRegression(np.array(stationElevFacet)[removeOutlierInds],\\\n",
    "                                                np.array(stationVarFacet[removeOutlierInds]),\\\n",
    "                                                np.array(finalWeightsFacet[removeOutlierInds]))\n",
    "                \n",
    "                                            \n",
    "                linFit[1] = metPoint.baseInterpField\n",
    "                \n",
    "                if np.isnan(linFit[0]):\n",
    "                    linFit[0] = defaultSlope\n",
    "                    tmpField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "                else:\n",
    "                    tmpField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "                \n",
    "                metPoint.rawField = tmpField\n",
    "                metPoint.slope = linFit[0]\n",
    "                metPoint.intercept = linFit[1]\n",
    "                metPoint.validRegress = 1\n",
    "                \n",
    "            else:\n",
    "                linFit=np.zeros([2,1])\n",
    "                linFit[0] = defaultSlope;\n",
    "                linFit[1] = metPoint.baseInterpField\n",
    "                \n",
    "                metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev);\n",
    "                metPoint.slope      = linFit[0]\n",
    "                metPoint.intercept  = linFit[1]\n",
    "            \n",
    "\n",
    "        elif np.isnan(linFit[0]):\n",
    "            linFit=np.zeros([2,1])\n",
    "            linFit[0] = defaultSlope\n",
    "            linFit[1] = metPoint.baseInterpField\n",
    "            \n",
    "            metPoint.rawField  = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "            metPoint.slope     = linFit[0]\n",
    "            metPoint.intercept = linFit[1]\n",
    "        else:           \n",
    "            \n",
    "            linFit[1] = metPoint.baseInterpField\n",
    "            \n",
    "            metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "            metPoint.slope     = linFit[0]\n",
    "            metPoint.intercept = linFit[1]\n",
    "            metPoint.validRegress = 1\n",
    "\n",
    "            #run through station combinations to estimate uncertainty in\n",
    "            #slope estimate\n",
    "            nSta = len(stationVarFacet)\n",
    "            combs = np.array(list(combinations(range(0, nSta), nSta-1)))\n",
    "            cnt = 1\n",
    "            combSlp = []\n",
    "                             \n",
    "                \n",
    "            for c in range(len(combs[:,0])):\n",
    "                X = np.c_[np.ones(len(np.array(stationElevFacet)[combs[c,:]])), np.array(stationElevFacet)[combs[c,:]]]\n",
    "                \n",
    "                #if X is square\n",
    "                if np.shape(X)[0]==np.shape(X)[1]:\n",
    "                    #if X is well conditioned\n",
    "                    if (np.linalg.cond(X))**-1 >tiny:\n",
    "                        tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                        elevSlopeTest = tmpLinFit[0]\n",
    "                    else:\n",
    "                        elevSlopeTest = large\n",
    "                    \n",
    "                else:\n",
    "                    tmpLinFit = calcWeightedRegression(np.array(stationElevFacet)[combs[c]],np.array(stationVarFacet)[combs[c]]\\\n",
    "                                                           ,np.array(finalWeightsFacet)[combs[c]])\n",
    "                    elevSlopeTest = tmpLinFit[0]\n",
    "                \n",
    "                \n",
    "                if(elevSlopeTest < maxSlopeLower and elevSlopeTest > minSlope and gridLayer == 1)\\\n",
    "                    or (elevSlopeTest<maxSlopeUpper and elevSlopeTest>minSlope and gridLayer == 2):\n",
    "                    combSlp.append(elevSlopeTest)\n",
    "                    cnt = cnt + 1\n",
    "                            \n",
    "            #if two or more valid combination of stations estimate uncertainty of slope at grid point using standard\n",
    "            #deviation of estimates\n",
    "            if (cnt-1) >= 2:\n",
    "                metPoint.slopeUncert = np.std(combSlp)\n",
    "            \n",
    "\n",
    "    else: #not enough stations within range on Facet - revert to nearest with default slope\n",
    "        linFit=np.zeros([2,1])\n",
    "        linFit[0] = defaultSlope\n",
    "        linFit[1] = metPoint.baseInterpField\n",
    "        \n",
    "        metPoint.rawField = np.polyval(linFit,gridElev-metPoint.baseInterpElev)\n",
    "        metPoint.slope     = linFit[0]\n",
    "        metPoint.intercept = linFit[1]\n",
    "\n",
    "     \n",
    "    return metPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4bf7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class structtype():\n",
    "    pass\n",
    "nearStations = structtype()\n",
    "coastWeights = structtype()\n",
    "topoPositionWeights = structtype()\n",
    "layerWeights = structtype()\n",
    "symapWeights = structtype()\n",
    "finalWeights = structtype()\n",
    "metPoint = structtype()\n",
    "\n",
    "#loop through all grid points and perform regression\n",
    "for y in range(0,grid.nr):   \n",
    "    for x in range(0,grid.nc):\n",
    "        if grid.mask[x,y] > 0:\n",
    "            \n",
    "            #find nearby stations to current grid point\n",
    "            nearStations = getNearStations(inputStations.meta.lat,inputStations.meta.lon,inputStations.meta.facet,\\\n",
    "                                           grid.lat[x,y],grid.lon[x,y],grid.facet[x,y],parameters.nMaxNear,\\\n",
    "                                           parameters.maxDist)\n",
    "\n",
    "            #compute coastal distance weights\n",
    "            stationDistanceToCoast_near= [inputStations.meta.coastDist[i] for i in nearStations.nearStationInds]\n",
    "            coastWeights.near = calcCoastWeights(grid.distToCoast[x,y],stationDistanceToCoast_near,parameters.coastalExp)\n",
    "\n",
    "            stationDistanceToCoast_facet= [inputStations.meta.coastDist[i] for i in nearStations.facetStationInds]\n",
    "            coastWeights.facet = calcCoastWeights(grid.distToCoast[x,y],stationDistanceToCoast_facet,parameters.coastalExp)\n",
    "\n",
    "            #compute topographic position weights\n",
    "            stationTopoPos_near= [inputStations.meta.topoPosition[i] for i in nearStations.nearStationInds]\n",
    "            topoPositionWeights.near = calcTopoPositionWeights(grid.topoPosition[x,y],parameters.topoPosMinDiff,\\\n",
    "                                                               parameters.topoPosMaxDiff,parameters.topoPosExp,\\\n",
    "                                                               stationTopoPos_near)\n",
    "\n",
    "            stationTopoPos_facet= [inputStations.meta.topoPosition[i] for i in nearStations.facetStationInds]\n",
    "            topoPositionWeights.facet = calcTopoPositionWeights(grid.topoPosition[x,y],parameters.topoPosMinDiff,\\\n",
    "                                                                parameters.topoPosMaxDiff,parameters.topoPosExp,\\\n",
    "                                                                stationTopoPos_facet)\n",
    "            #compute layer weights\n",
    "            stationLayer_near = [inputStations.meta.layer[i] for i in nearStations.nearStationInds]\n",
    "            stationElev_near = [inputStations.meta.elev[i] for i in nearStations.nearStationInds]\n",
    "            layerWeights.near = calcLayerWeights(grid.layerMask[x,y],grid.dem[x,y],stationLayer_near,stationElev_near,\\\n",
    "                                                 parameters.layerExp)\n",
    "\n",
    "            stationLayer_facet = [inputStations.meta.layer[i] for i in nearStations.facetStationInds]\n",
    "            stationElev_facet = [inputStations.meta.elev[i] for i in nearStations.facetStationInds]\n",
    "            layerWeights.facet = calcLayerWeights(grid.layerMask[x,y],grid.dem[x,y],stationLayer_facet,stationElev_facet,\\\n",
    "                                                  parameters.layerExp)\n",
    "\n",
    "\n",
    "            #compute SYMAP weights\n",
    "            symapWeights.near = calcSymapWeights(nearStations.staDist[nearStations.nearStationInds],\\\n",
    "                                                 nearStations.staAngles[nearStations.nearStationInds],\\\n",
    "                                                 parameters.distanceWeightScale,parameters.distanceWeightExp,\\\n",
    "                                                 parameters.maxDist)\n",
    "\n",
    "            symapWeights.facet = calcSymapWeights(nearStations.staDist[nearStations.facetStationInds],\\\n",
    "                                                  nearStations.staAngles[nearStations.facetStationInds],\\\n",
    "                                                  parameters.distanceWeightScale,parameters.distanceWeightExp,\\\n",
    "                                                  parameters.maxDist)\n",
    "\n",
    "            #compute final weights\n",
    "            finalWeights.near = calcFinalWeights(controlVars.variableEstimated,symapWeights.near,coastWeights.near,\\\n",
    "                                                 topoPositionWeights.near,layerWeights.near)\n",
    "            finalWeights.facet = calcFinalWeights(controlVars.variableEstimated,symapWeights.facet,coastWeights.facet,\\\n",
    "                                                  topoPositionWeights.facet,layerWeights.facet)\n",
    "\n",
    "\n",
    "\n",
    "            #compute first pass met field on grid\n",
    "            if controlVars.variableEstimated=='precip':\n",
    "                #compute met fields at current grid point for precipitation\n",
    "                stationElevFacet = [inputStations.meta.elev[i] for i in nearStations.facetStationInds]\n",
    "                stationElevNear = [inputStations.meta.elev[i] for i in nearStations.nearStationInds]\n",
    "                metPoint = calcPrecip(parameters,grid.smoothDemKM[x,y],parameters.defaultSlope,finalWeights.near,\\\n",
    "                                      finalWeights.facet,symapWeights.near,stationElevNear,stationElevFacet,\\\n",
    "                                      inputStations.avgVar[nearStations.nearStationInds],\\\n",
    "                                      inputStations.avgVar[nearStations.facetStationInds])\n",
    "\n",
    "\n",
    "                #set precipitation specific output variables\n",
    "                metGrid.normSlopeUncert[x,y] = metPoint.normSlopeUncert\n",
    "                metGrid.normSlope[x,y]       = metPoint.normSlope\n",
    "\n",
    "            elif (controlVars.variableEstimated=='tmax') or (controlVars.variableEstimated=='tmin'):\n",
    "                #compute met fields at current grid point for temperature\n",
    "                metPoint = calcTemp(parameters,grid.smoothDemKM[x,y],tempDefaultLapse[x,y],grid.layerMask[x,y],\\\n",
    "                                    finalWeights.near,finalWeights.facet,symapWeights.near,\\\n",
    "                                   [inputStations.meta.elev[i] for i in nearStations.nearStationInds],\\\n",
    "                                    [inputStations.meta.elev[i] for i in nearStations.facetStationInds],\\\n",
    "                                    inputStations.avgVar[nearStations.nearStationInds],\\\n",
    "                                    inputStations.avgVar[nearStations.facetStationInds])\n",
    "\n",
    "\n",
    "            #set metGrid values for current grid point\n",
    "            metGrid.rawField[x,y]            = metPoint.rawField\n",
    "            metGrid.intercept[x,y]           = metPoint.intercept\n",
    "            metGrid.slope[x,y]               = metPoint.slope\n",
    "            metGrid.baseInterpField[x,y]     = metPoint.baseInterpField\n",
    "            metGrid.baseInterpElev[x,y]      = metPoint.baseInterpElev\n",
    "            metGrid.baseInterpUncert[x,y]    = metPoint.baseInterpUncert\n",
    "            metGrid.slopeUncert[x,y]         = metPoint.slopeUncert\n",
    "            metGrid.validRegress[x,y]        = metPoint.validRegress\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56e235e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g/g.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae2460",
   "metadata": {},
   "source": [
    "# updatePrecipSlope:\n",
    "* *updates the estimated slope (elevation lapse rate) of precipitation across the grid from the initial estimate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb124887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatePrecipSlope(nr,nc,mask,normSlope,validSlope,defaultSlope,recomputeDefault,filterSize,filterSpread):\n",
    "    \"\"\"\n",
    "     updatePrecipSlope updates the estimated slope (elevation lapse rate) of \n",
    "     precipitation across the grid from the initial estimate\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Inputs: nr, integer,   number of rows in grid\n",
    "       nc, integer,   number of columns in grid\n",
    "       mask, integer, mask of valid grid points\n",
    "       normslope, float, intial normalized slope estimate across grid\n",
    "       validSlope, integer, mask of valid regression estimated slopes\n",
    "       defaultSlope, float, value of the default normalized precipitation\n",
    "                            slope \n",
    "       recomputeDefault,string, string indicating true/false to recompute the\n",
    "                            default normalized precipitation slope\n",
    "       filterSize, integer, size of low-pass filter in grid points\n",
    "       filterSpread, float, variance of low-pass filter\n",
    "\n",
    "      Outputs: finalNormSlope, structure, structure containing the final normalized \n",
    "                                  slope for all grid points for precip variables\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #if user specifies to recompute the default slope then do it use only points that had valid regression based slopes\n",
    "    #ideally this is an improvement over a specified default slope\n",
    "    \n",
    "    if recomputeDefault=='true':\n",
    "        baseSlope = normSlope\n",
    "        baseSlope[validSlope!=1] = -999\n",
    "        domainMeanSlope = np.mean(np.mean(baseSlope[baseSlope != -999]))\n",
    "        baseSlope[baseSlope == -999] = domainMeanSlope\n",
    "    else:\n",
    "        baseSlope = normSlope\n",
    "        baseSlope[validSlope!=1] = defaultSlope\n",
    "\n",
    "\n",
    "    #filter and interpolate slopes to entire domain \n",
    "    #this is a similar step to the Daly et al. (1994) feathering except it is applied to the precipitation slopes.\n",
    "    #This is done before feathering, where feathering is a final check for precipitation gradients\n",
    "\n",
    "    #define a mesh of indicies for scattered interpolation of valid points back to a grid\n",
    "    x = range(0,nc)\n",
    "    y = range(0,nr)\n",
    "\n",
    "    x2d,y2d = np.meshgrid(y,x)\n",
    "\n",
    "    #find valid grid points\n",
    "    j,i=np.where(baseSlope > 0)\n",
    "    #scattered interpolation using griddata\n",
    "    interpBaseSlope = griddata((i,j),baseSlope[baseSlope>0],(x2d,y2d),'linear')\n",
    "\n",
    "\n",
    "    #fill missing values with the average of elements\n",
    "    interpBaseSlope= np.nan_to_num(interpBaseSlope, nan=np.nanmean(interpBaseSlope))\n",
    "    #interpBaseSlope = fillmissing(interpBaseSlope,'nearest',2)\n",
    "\n",
    "\n",
    "    #define gaussian low-pass filter\n",
    "    gFilter = fspecial_gauss(filterSize,filterSpread)\n",
    "\n",
    "    #filter slope estimate\n",
    "    filterSlope= ndimage.convolve(interpBaseSlope, gFilter, mode='wrap', cval=0)\n",
    "\n",
    "\n",
    "    #set unused grid points to missing\n",
    "    filterSlope[mask<=0] = -999\n",
    "\n",
    "    #set output variable\n",
    "    finalNormSlope = filterSlope\n",
    "    \n",
    "    \n",
    "    return finalNormSlope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc30bb",
   "metadata": {},
   "source": [
    "# featherPrecip:\n",
    "* *updates the estimated precipitation field to remove sharp, potentially unrealistic gradients due primarily do to slope facet processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d411b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featherPrecip(parameters,nr,nc,dx,dem,mask,finalNormSlope,baseInterpPrecip,baseInterpElev):\n",
    "    \"\"\"\n",
    "     featherPrecip updates the estimated precipitation field to remove sharp, potentially unrealistic gradients \n",
    "     due primarily do to slope facet processing. Generally follows Daly et al.(1994).  \n",
    "     This is the final precipitation processing step.\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Inputs: parameters, structure, tier parameter structure\n",
    "       dxy, float, grid spacing (km) of grid\n",
    "       dem, float, grid dem\n",
    "       mask, integer, mask of valid grid points\n",
    "       finalNormslope, float, final normalized slope estimate across grid\n",
    "       baseInterpPrecip, float,    baseInterp weighted estimated precipitation \n",
    "       baseInterpElev, float, elevation of baseInterp weighted stations for baseInterp estimate\n",
    "\n",
    "      Outputs: finalPrecip, float, grid containing the final precipitation estimate\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    #compute precipitation again, using spatially interpolated valid slopes,\n",
    "    #rather than a mishmash of valid and default values from grid point to grid point\n",
    "    finalPrecip = np.multiply(np.multiply(finalNormSlope,baseInterpPrecip),(dem-baseInterpElev)) + baseInterpPrecip\n",
    "    finalSlope = np.multiply(finalNormSlope,baseInterpPrecip)\n",
    "\n",
    "    #Now check to see if any feathering is needed to relax potentially large grid cell to grid-cell gradients\n",
    "    #that may be non-physical.  generally follows Daly et al. (1994)\n",
    "\n",
    "    #Here a check of the grid elevation is made to prevent excessive\n",
    "    #feathering across low and flat elevations.  This may be because of\n",
    "    #some bug in the algorithm, or some other unknown issue.  This check\n",
    "    #does not appear to be in Daly et al. (1994)\n",
    "\n",
    "\n",
    "\n",
    "    #set parameter values from input parameter structure\n",
    "    #buffer to add to slope change to make sure gradient falls under max_grad when changed\n",
    "    bufferSlope = parameters.bufferSlope \n",
    "    maxFinalSlope = parameters.maxFinalSlope  #max normalized slope (Daly et al. 1994)\n",
    "    maxGrad = parameters.maxGrad  #normalized slope per km  #each grid cell is dx apart\n",
    "    demMaxGrad = maxGrad/dx.filled() #grid relative gradient\n",
    "    minElevDiff = parameters.minElevDiff #km\n",
    "    minElev = parameters.minElev #km\n",
    "\n",
    "    #first, set negative and zero pcp to mean value\n",
    "    negInds = np.where(finalPrecip<=0)\n",
    "    if np.size(negInds)!=0:\n",
    "        finalPrecip[negInds] = baseInterpPrecip[negInds]\n",
    "\n",
    "\n",
    "    #second need to make sure all the precipitation slopes are within reasonable bounds\n",
    "    inds = np.where(finalNormSlope>maxFinalSlope)\n",
    "    if np.size(inds)!=0:\n",
    "        #reset values to valid final maximum slope\n",
    "        finalSlope[inds] = maxFinalSlope*baseInterpPrecip[inds]\n",
    "\n",
    "        #recompute precipitation field using updated slopes\n",
    "        for i in  range(len(inds)):\n",
    "            finalPrecip[inds[i]] = np.polyval(np.c_[finalSlope[inds],baseInterpPrecip[inds]][:,i],dem[inds][i]-baseInterpElev[inds][i])\n",
    "\n",
    "\n",
    "    #now check spatial gradients for exceedance\n",
    "    #recompute normalized slopes in a temporary variable\n",
    "    tmpNormSlope = np.divide(finalSlope,baseInterpPrecip)\n",
    "    #temporary precipitation variable\n",
    "    tmpPrecip = finalPrecip.filled(np.nan)\n",
    "    tmpNormSlope[mask<0]=np.nan\n",
    "\n",
    "    #keep track of passes and number of grid points modified\n",
    "    pass1 = 1\n",
    "    numgridModified = 1\n",
    "    while numgridModified > 0:\n",
    "        numgridModified = 0\n",
    "        #loop across grid\n",
    "        for x in range(1,nr-1):\n",
    "            if np.mod(x,100)==0:\n",
    "                print('Done with pass %d, row: %d\\n'%(pass1,y))\n",
    "\n",
    "            for y in range(1,nc-1):\n",
    "\n",
    "                #compute gradients using trailing pt (backward finite difference)\n",
    "\n",
    "                #two step process: East-West graident first\n",
    "                ewGrad = tmpNormSlope[y,x]-tmpNormSlope[y-1,x]\n",
    "\n",
    "                #if the gradient exceeds the allowable gradient and the elevation is above minimum and the difference\n",
    "                #across grid cell elevations is large enough then feather grid point\n",
    "                if (abs(ewGrad)> demMaxGrad) and ((abs(dem[y,x]- dem[y-1,x])>minElevDiff) or (dem[y,x]>minElev)):\n",
    "                    #define static fields\n",
    "                    tmpIntercept = [baseInterpPrecip[y,x], baseInterpPrecip[y-1,x]]\n",
    "                    tmpElev = [baseInterpElev[y,x], baseInterpElev[y-1,x]]\n",
    "                    tmpDem = [dem[y,x], dem[y-1,x]]\n",
    "\n",
    "                    #define fields that will be updated\n",
    "                    tmpPrecipArray = [tmpPrecip[y,x], tmpPrecip[y-1,x]]\n",
    "                    tmpSlopeArray = [tmpNormSlope[y,x], tmpNormSlope[y-1,x]]\n",
    "\n",
    "\n",
    "                    #which point has smaller precipitation\n",
    "                    lowInd = np.argmin(tmpPrecipArray)\n",
    "\n",
    "                    #if the slope of the lower precipitation estimate is valid\n",
    "                    if tmpSlopeArray[lowInd]>=maxFinalSlope:\n",
    "                        #find the index of the minimum slope point\n",
    "                        lowInd = np.argmin(tmpSlopeArray);\n",
    "\n",
    "                        #feather (smooth) the slope gradient using the valid slope\n",
    "                        tmpPtSlope = ((abs(ewGrad)-demMaxGrad)+bufferSlope+tmpSlopeArray[lowInd])\n",
    "                        #recompute precipitation with smoothed slope\n",
    "\n",
    "\n",
    "                        tmpPtPrecip = np.polyval(np.c_[tmpPtSlope*tmpIntercept[lowInd],tmpIntercept[lowInd]],\\\n",
    "                                                 tmpDem[lowInd]-tmpElev[lowInd])\n",
    "\n",
    "                        #update the precipitation and slope values\n",
    "                        tmpPrecip[y-lowInd,x] = tmpPtPrecip\n",
    "                        tmpNormSlope[y-lowInd,x] = tmpPtSlope\n",
    "                    else:\n",
    "                        #if the slope of the lower precipitation estimate is not valid\n",
    "                        #feather the gradient using lower precipitation grid point slope.  \n",
    "                        #this will eventually smooth gradients out across enough grid points given enough passes\n",
    "                        tmpPtSlope = ((abs(ewGrad)-demMaxGrad)+bufferSlope+tmpSlopeArray[lowInd])\n",
    "                        tmpPtPrecip = np.polyval(np.c_[tmpPtSlope*tmpIntercept[lowInd],tmpIntercept[lowInd]],\\\n",
    "                                                 tmpDem[lowInd]-tmpElev[lowInd])\n",
    "\n",
    "                        #update precipitation and slope values\n",
    "                        tmpPrecip[y-lowInd,x] = tmpPtPrecip\n",
    "                        tmpNormSlope[y-lowInd,x] = tmpPtSlope\n",
    "                    # end temporary slope check if statement \n",
    "\n",
    "                    #increment counter tracking number of point modifications\n",
    "                    numgridModified = numgridModified + 1\n",
    "                 #end precipitation gradient check\n",
    "\n",
    "                #North-South second using updated precipitation and slope \n",
    "                #if the East-West gradient feathering changed things\n",
    "                #compute North-South gradient\n",
    "                nsGrad = tmpNormSlope[y,x]-tmpNormSlope[y,x-1]\n",
    "\n",
    "\n",
    "                #if the gradient exceeds the allowable gradient\n",
    "                #and the elevation is above minimum and the difference\n",
    "                #across grid cell elevations is large enough\n",
    "                #then feather grid point\n",
    "                if abs(nsGrad)>demMaxGrad and ((abs(dem[y,x]-dem[y,x-1])>minElevDiff) or (dem(y,x)>minElev)):\n",
    "                    #set static fields\n",
    "                    tmpIntercept = [baseInterpPrecip[y,x], baseInterpPrecip(y,x-1)]\n",
    "                    tmpElev      = [baseInterpElev[y,x], baseInterpElev(y,x-1)]\n",
    "                    tmpDem       = [dem[y,x], dem[y,x-1]]\n",
    "\n",
    "                    #set updated fields\n",
    "                    tmpPrecipArray = [tmpPrecip[y,x], tmpPrecip[y,x-1]]\n",
    "                    tmpSlopeArray = [tmpNormSlope[y,x], tmpNormSlope[y,x-1]]\n",
    "\n",
    "                    #which point is lower precipitation\n",
    "                    lowInd = np.argmin(tmpPrecipArray)\n",
    "\n",
    "                    #if the slope of the lower precipitation estimate is valid\n",
    "                    if tmpSlopeArray[lowInd]>=maxFinalSlope:\n",
    "                        #find the index of the minimum slope point\n",
    "                        lowInd = np.argmin(tmpSlopeArray)\n",
    "                        #feather (smooth) the slope gradient using the valid slope\n",
    "                        tmpPtSlope = ((abs(nsGrad)-demMaxGrad)+bufferSlope+tmpSlopeArray[lowInd])\n",
    "                        tmpPtPrecip = np.polyval(np.c_[tmpPtSlope*tmpIntercept[lowInd],tmpIntercept[lowInd]],\\\n",
    "                                                 tmpDem[lowInd]-tmpElev[lowInd])\n",
    "                        #recompute precipitation with smoothed slope\n",
    "                        tmpPrecip[y,x-lowInd+1] = tmpPtPrecip\n",
    "                        tmpNormSlope[y,x-lowInd+1] = tmpPtSlope\n",
    "                    else:\n",
    "                        #if the slope of the lower precipitation estimate is not valid\n",
    "                        #feather the gradient using lower precipitation grid point slope.  \n",
    "                        #this will eventually smooth gradients out across enough grid points given enough passes\n",
    "                        tmpPtSlope = ((abs(nsGrad)-demMaxGrad)+bufferSlope+tmpSlopeArray[lowInd])\n",
    "                        tmpPtPrecip = np.polyval(np.c_[tmpPtSlope*tmpIntercept[lowInd],tmpIntercept[lowInd]],\\\n",
    "                                                       tmpDem[lowInd]-tmpElev[lowInd])\n",
    "\n",
    "                        #update precipitation and slope values\n",
    "                        tmpPrecip[y,x-lowInd+1] = tmpPtPrecip\n",
    "                        tmpNormSlope[y,x-lowInd+1] = tmpPtSlope\n",
    "\n",
    "                    #increment counter tracking number of point\n",
    "                    #modifications\n",
    "                    numgridModified = numgridModified + 1\n",
    "\n",
    "                 #gradient check\n",
    "\n",
    "             #x\n",
    "         #y\n",
    "        #increment pass counter\n",
    "        pass1 = pass1 + 1;\n",
    "        print('%d points modified\\n'%numgridModified)\n",
    "      #passes\n",
    "\n",
    "\n",
    "    #finally recheck any negative and zero pcp to mean value\n",
    "    negInds = np.where(tmpPrecip<=0)\n",
    "    if np.size(negInds)!=0:\n",
    "        tmpPrecip[negInds] = baseInterpPrecip[negInds]\n",
    "\n",
    "    #set final precipitation\n",
    "    finalPrecip = tmpPrecip\n",
    "    #invalid grid points set to missing\n",
    "    finalPrecip[mask<0] = -999\n",
    "\n",
    "    return finalPrecip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43043973",
   "metadata": {},
   "source": [
    "# calcFinalPrecipUncert:\n",
    "* *produces the final component uncertainty estimates as well as the final total and relative uncertainty accounting for covariance between the components of the total*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca57b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFinalPrecipUncert(grid,baseInterpUncert,baseInterpElev,slopeUncert,finalVar,filterSize,filterSpread,covWindow):\n",
    "    \n",
    "    \"\"\"\n",
    "     calcFinalPrecipUncert produces the final component uncertainty estimates as well as the final total \n",
    "     and relative uncertainty accounting for covariance between the components of the total\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Inputs: grid, structure, structure containing grid information\n",
    "       baseInterpUncert, float, baseInterp precipitation uncertainty estimate (mm timestep-1)\n",
    "       slopeUncert, float, estimated uncertainty of slope (elev lapse rate) in normalized space\n",
    "       finalVar, float, final variable estimate (precip here)\n",
    "       filterSize, integer, size of low-pass filter in grid points\n",
    "       filterSpread, float, variance of low-pass filter\n",
    "       covWindow, float, size (grid points) of covariance window\n",
    "\n",
    "      Outputs: finalUncert, structure, structure containing the final components\n",
    "               and the total and relative precipitation uncertainty estimates\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "    \n",
    "    \"\"\"\n",
    "    #use only points that had valid uncertainty estimates from the base\n",
    "    #baseInterp interpolation or the weighted regression, then filter and interpolate to entire domain \n",
    "    #this estimates uncertainty at each grid point from points where we\n",
    "    #actually have initial estimates also smooths out high-frequency noise\n",
    "\n",
    "\n",
    "    class structtype():\n",
    "        pass\n",
    "    finalUncert = structtype()    \n",
    "\n",
    "    #define a mesh of indicies for scattered interpolation of valid points back to a grid\n",
    "    y = range(0,grid.nr)\n",
    "    x = range(0,grid.nc)\n",
    "    x2d,y2d = np.meshgrid(y,x)\n",
    "\n",
    "    #find valid baseInterpUncert points\n",
    "    j,i=np.where(baseInterpUncert > 0)\n",
    "\n",
    "    #scattered interpolation using griddata\n",
    "    interpBaseInterp =griddata((i,j),baseInterpUncert[baseInterpUncert>=0],(x2d,y2d),'linear')\n",
    "    #fill missing values with nearest neighbor\n",
    "\n",
    "    interpBaseInterp = np.nan_to_num(interpBaseInterp, nan=np.nanmean(interpBaseInterp))\n",
    "\n",
    "    #find valid slopeUncert points\n",
    "    j,i = np.where(slopeUncert >= 0) \n",
    "\n",
    "    #scattered interpolation using griddata\n",
    "    interpSlope = griddata((i,j),slopeUncert[slopeUncert>=0],(x2d,y2d),'linear')\n",
    "\n",
    "    #fill missing values with nearest neighbor\n",
    "    interpSlope = np.nan_to_num(interpSlope, nan=np.nanmean(interpSlope))\n",
    "\n",
    "\n",
    "    #generate gaussian low-pass filter\n",
    "    gFilter = fspecial_gauss(filterSize,filterSpread)\n",
    "\n",
    "\n",
    "    #filter uncertainty estimates\n",
    "    finalBaseInterpUncert = ndimage.convolve(interpBaseInterp, gFilter, mode='wrap', cval=0)\n",
    "    finalSlopeUncert = ndimage.convolve(interpSlope, gFilter, mode='wrap', cval=0)\n",
    "\n",
    "\n",
    "    #estimate the total and relative uncertainty in physical units (mm timestep-1)\n",
    "    #compute slope in physical space\n",
    "    baseSlopeUncert = np.multiply(np.multiply(finalSlopeUncert,finalVar),abs(baseInterpElev-(grid.smoothDem/1000))) #need to have dem in km\n",
    "\n",
    "    baseSlopeUncert= np.nan_to_num(baseSlopeUncert, nan=np.nanmean(baseSlopeUncert))\n",
    "\n",
    "\n",
    "    #replace nonvalid mask points with NaN\n",
    "    baseSlopeUncert[grid.mask<=0] = np.nan\n",
    "    finalBaseInterpUncert[grid.mask<=0] = np.nan\n",
    "\n",
    "    #define a local covariance vector\n",
    "    localCov = np.zeros(np.shape(finalBaseInterpUncert))*np.nan\n",
    "\n",
    "    #step through each grid point and estimate the local covariance between\n",
    "    #the two uncertainty components using covWindow to define the size of the local covariance estimate\n",
    "    #covariance influences the total combined estimate\n",
    "    for i in range(grid.nr):\n",
    "        for j in range(grid.nc):\n",
    "            #define indicies aware of array bounds\n",
    "            jInds = [max(0, i-covWindow),min(grid.nr,i+covWindow)]\n",
    "            iInds = [max(0, j-covWindow),min(grid.nc,j+covWindow)]\n",
    "\n",
    "            #compute local covariance using selection of valid points get windowed area\n",
    "            subBaseInterp = finalBaseInterpUncert[int(iInds[0]):int(iInds[1]),int(jInds[0]):int(jInds[1])]\n",
    "            subSlope = baseSlopeUncert[int(iInds[0]):int(iInds[1]),int(jInds[0]):int(jInds[1])]\n",
    "            #compute covariance for only valid points in window\n",
    "            c = np.cov(subBaseInterp[np.isnan(subBaseInterp)==False],subSlope[np.isnan(subSlope)==False])\n",
    "            #pull relevant value from covariance matrix\n",
    "            localCov[j,i] = c[0,len(c[0,:])-1]\n",
    "\n",
    "\n",
    "\n",
    "    #compute the total estimates \n",
    "    finalUncert.totalUncert = baseSlopeUncert+finalBaseInterpUncert+2*np.sqrt(abs(localCov))\n",
    "    finalUncert.relativeUncert = np.divide(finalUncert.totalUncert,finalVar)\n",
    "\n",
    "    #set novalid gridpoints to missing \n",
    "    finalBaseInterpUncert[grid.mask<=0] = -999\n",
    "    finalUncert.totalUncert[grid.mask<=0] = -999\n",
    "    finalUncert.relativeUncert[grid.mask<=0] = -999\n",
    "\n",
    "    #define components in output structure\n",
    "    finalUncert.finalBaseInterpUncert = finalBaseInterpUncert\n",
    "    finalUncert.finalSlopeUncert = baseSlopeUncert\n",
    "   \n",
    "    \n",
    "    return finalUncert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692447d",
   "metadata": {},
   "source": [
    "# updateTempSlope:\n",
    "* *updates the estimated slope (elevation lapse rate) of temperature variables across the grid from the initial estimate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89dac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTempSlope(nr,nc,mask,gridLayer,slope,recomputeDefault,defaultSlope,\\\n",
    "                    validSlope,minSlope,maxSlopeLower,maxSlopeUpper,filterSize,filterSpread):\n",
    "    \"\"\"\n",
    "     updateTempSlope updates the estimated slope (elevation lapse rate) of temperature \n",
    "     variables across the grid from the initial estimate\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Inputs: nr, integer,   number of rows in grid\n",
    "       nc, integer,   number of columns in grid\n",
    "       mask, integer, mask of valid grid points\n",
    "       slope, float, intial slope estimate across grid\n",
    "       defaultSlope, float, default estimate of slope across grid\n",
    "       recomputeDefault,string, string indicating true/false to recompute the\n",
    "       default normalized precipitation slope validSlope, integer, mask of valid regression estimated slopes\n",
    "       minSlope, float, minimum valid slope (TIER parameter)\n",
    "       maxSlopeLower, float, maximum lower layer valid slope (TIER parameter)\n",
    "       maxSlopeUpper, float, maximum upper layer valid slope (TIER parameter)\n",
    "       filterSize, integer, size of low-pass filter in grid points\n",
    "       filterSpread, float, variance of low-pass filter\n",
    "\n",
    "      Outputs: finalSlope, structure, structure containing the final slope for all\n",
    "               grid points for temp variables\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #if user specifies to recompute the default slope and there is\n",
    "    #no user specified spatially variable lapse rate file (this check is performed in the driver)\n",
    "    #use only points that had valid regression based slopes\n",
    "    #ideally this is an improvement over a specified default slope\n",
    "    if recomputeDefault=='true':\n",
    "        baseSlope = slope\n",
    "        baseSlope[validSlope!=1] = -999\n",
    "        domainMeanSlope = np.mean(np.mean(baseSlope[baseSlope != -999]))\n",
    "        baseSlope[baseSlope == -999] = domainMeanSlope\n",
    "    else:\n",
    "        baseSlope = slope\n",
    "        if len(defaultSlope[:,0]>1):\n",
    "            baseSlope[validSlope!=1] = defaultSlope[validSlope!=1]\n",
    "        else:\n",
    "            baseSlope[validSlope!=1] = defaultSlope\n",
    "            \n",
    "\n",
    "\n",
    "    #define a mesh of indicies for scattered interpolation of valid points back to a grid\n",
    "    y = range(0,nr)\n",
    "    x = range(0,nc)\n",
    "    x2d,y2d = np.meshgrid(y,x)\n",
    "\n",
    "    #perform 2 scattered interpolations to get final slope, one for layer 1, one for layer2\n",
    "    \n",
    "    #find valid points for layer 1\n",
    "    j,i=np.where((baseSlope >= minSlope) & (gridLayer == 1))\n",
    "    \n",
    "    #scattered interpolation using griddata\n",
    "    interpSlopeLayer1 = griddata((i,j),baseSlope[(baseSlope>= minSlope) & (gridLayer == 1)],(x2d,y2d),'linear')\n",
    "    #fill missing values with nearest neighbor\n",
    "\n",
    "    interpSlopeLayer1 = np.nan_to_num(interpSlopeLayer1, nan=np.nanmean(interpSlopeLayer1))\n",
    "    \n",
    "    #find valid points for layer 2\n",
    "    [i,j] = np.where((baseSlope >= minSlope) & (gridLayer == 2))\n",
    "    #scattered interpolation using griddata\n",
    "    interpSlopeLayer2 = griddata((i,j),baseSlope[(baseSlope>= minSlope) & (gridLayer == 2)],(x2d,y2d),'linear')\n",
    "    #fill missing values with nearest neighbor\n",
    "\n",
    "    interpSlopeLayer2 = np.nan_to_num(interpSlopeLayer2, nan=np.nanmean(interpSlopeLayer2))\n",
    "    \n",
    "    #define gaussian low-pass filter\n",
    "    gFilter = fspecial_gauss(filterSize,filterSpread)\n",
    "    \n",
    "    \n",
    "    #filter the combined field\n",
    "    filterSlope = interpSlopeLayer1\n",
    "    filterSlope[gridLayer == 2] = interpSlopeLayer2[gridLayer == 2]\n",
    "\n",
    "    filterSlope = ndimage.convolve(filterSlope, gFilter, mode='wrap', cval=0)\n",
    "    \n",
    "\n",
    "    #check for invalid slopes\n",
    "    filterSlopeLayer1 = filterSlope\n",
    "    filterSlopeLayer1[filterSlopeLayer1 > maxSlopeLower] = maxSlopeLower\n",
    "    filterSlopeLayer1[filterSlopeLayer1 < minSlope] = minSlope\n",
    "    #set unused points to missing\n",
    "    filterSlopeLayer1[mask<=0] = -999\n",
    "    \n",
    "    #check for invalid slopes\n",
    "    filterSlopeLayer2 = filterSlope\n",
    "    filterSlopeLayer2[filterSlopeLayer2 > maxSlopeUpper] = maxSlopeUpper\n",
    "    filterSlopeLayer2[filterSlopeLayer2 < minSlope] = minSlope\n",
    "    #set unused points to missing\n",
    "    filterSlopeLayer2[mask<=0] = -999\n",
    "    \n",
    "    #combine the two layer estimates into one complete grid\n",
    "    finalSlope = filterSlopeLayer1\n",
    "    finalSlope[gridLayer == 2] = filterSlopeLayer2[gridLayer == 2]\n",
    "\n",
    "    return finalSlope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70071d",
   "metadata": {},
   "source": [
    "# calcFinalTemp:\n",
    "* *computes the final temperature grid after all adjustmentse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a6690d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFinalTemp(dem,mask,baseInterpElev,baseInterpTemp,finalSlope):\n",
    "    \"\"\"\n",
    "     calFinalTemp computes the final temperature grid after all adjustments\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Inputs: dem,  float  , grid dem\n",
    "       mask, integer, mask of valid grid points\n",
    "\n",
    "       baseInterpElev, float, elevation of baseInterp weighted stations for baseInterp estimate\n",
    "       baseInterpTemp, float, baseInterp estimated temperature\n",
    "       finaSlope, float, grid of final slope estimates after any previous adjustments \n",
    "\n",
    "      Outputs: finalTemp, structure, structure containing the final temperature\n",
    "                             estimate across the grid\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #compute final temp using all finalized estimates\n",
    "    finalTemp = np.multiply(finalSlope,(dem-baseInterpElev) ) + baseInterpTemp\n",
    "    #set unused grid points to missing\n",
    "    finalTemp[mask<0] = -999\n",
    "    \n",
    "    return finalTemp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b151aa",
   "metadata": {},
   "source": [
    "# calcFinalTempUncert:\n",
    "* *computes the final uncertainty for temperature variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c33cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFinalTempUncert(grid,baseInterpUncert,baseInterpElev,slopeUncert,filterSize,filterSpread,covWindow):\n",
    "    \"\"\"\n",
    "     calcFinalTempUncert computes the final uncertainty for temperature variables\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Inputs: grid, structure, structure containing grid information\n",
    "       baseInterpUncert, float, intiial baseInterp uncertainty estimate across grid\n",
    "       slopeUncert, float, initial estimate of slope uncertainty across grid\n",
    "       filterSize, integer, size of low-pass filter in grid points\n",
    "       filterSpread, float, variance of low-pass filter\n",
    "       covWindow, float, size (grid points) of covariance window\n",
    "\n",
    "      Outputs: finalUncert, structure, structure containing total and relative\n",
    "                               uncertainty for met var\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "    \"\"\"\n",
    "    \n",
    "    #define a mesh of indicies for scattered interpolation of valid points back to a grid\n",
    "    y = range(0,nr)\n",
    "    x = range(0,nc)\n",
    "    x2d,y2d = np.meshgrid(y,x)\n",
    "\n",
    "    #find valid points for baseInterp uncertainty\n",
    "    j,i = np.where(np.isnan(baseInterpUncert)== False)\n",
    "    #scattered interpolation using griddata\n",
    "    interpBaseInterp = griddata((i,j),baseInterpUncert[np.isnan(baseInterpUncert)==False],(x2d,y2d),'linear')\n",
    "    #fill missing values with nearest neighbor\n",
    "    interpBaseInterp = np.nan_to_num(interpBaseInterp, nan=np.nanmean(interpBaseInterp))  \n",
    "    \n",
    "    #find valid points for slope uncertaintty\n",
    "    j,i = np.where(slopeUncert >= 0)\n",
    "    #scattered interpolation using griddata\n",
    "    interpSlope = griddata((i,j),slopeUncert[slopeUncert>=0],(x2d,y2d),'linear');\n",
    "    interpSlope = np.multiply(interpSlope,abs(baseInterpElev-grid.smoothDem))\n",
    "    #fill missing values with nearest neighbor\n",
    "\n",
    "    interpSlope = np.nan_to_num(interpSlope, nan=np.nanmean(interpSlope)) \n",
    "    \n",
    "    \n",
    "    #gaussian low-pass filter\n",
    "    gFilter =  fspecial_gauss(filterSize,filterSpread)\n",
    "    \n",
    "    #filter uncertainty estimates\n",
    "    finalBaseInterpUncert = ndimage.convolve(interpBaseInterp, gFilter, mode='wrap', cval=0)\n",
    "    finalSlopeUncert = ndimage.convolve(interpSlope, gFilter, mode='wrap', cval=0)\n",
    "\n",
    "    \n",
    "    #replace nonvalid mask points with NaN\n",
    "    finalBaseInterpUncert[grid.mask<=0]= np.nan\n",
    "    finalSlopeUncert[grid.mask<=0] = np.nan\n",
    "    \n",
    "    #estimate the total and relative uncertainty in physical units \n",
    "    #define a local covariance vector\n",
    "    localCov =np.zeros(np.shape(finalBaseInterpUncert))*np.nan\n",
    "\n",
    "    #step through each grid point and estimate the local covariance between\n",
    "    #the two uncertainty components using covWindow to define the size of the local covariance estimate\n",
    "    #covariance influences the total combined estimate\n",
    "    for i in range(grid.nr):\n",
    "        for j in range(grid.nc):\n",
    "            #define indicies aware of array bounds\n",
    "            jInds = [max(0, i-covWindow),min(grid.nr,i+covWindow)]\n",
    "            iInds = [max(0, j-covWindow),min(grid.nc,j+covWindow)]\n",
    "\n",
    "            #compute local covariance using selection of valid points\n",
    "            #get windowed area\n",
    "            subBaseInterp = finalBaseInterpUncert[int(iInds[0]):int(iInds[1]),int(jInds[0]):int(jInds[1])]\n",
    "            subSlope = finalSlopeUncert[int(iInds[0]):int(iInds[1]),int(jInds[0]):int(jInds[1])]\n",
    "            #compute covariance for only valid points in window\n",
    "            c = np.cov(subBaseInterp[np.isnan(subBaseInterp)==False],subSlope[np.isnan(subSlope)==False])\n",
    "            #pull relevant value from covariance matrix\n",
    "            localCov[i,j] = c[0,len(c[0,:])-1]      \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "    #compute the total estimates \n",
    "    finalUncert.totalUncert = finalSlopeUncert+finalBaseInterpUncert+2*np.sqrt(abs(localCov))\n",
    "    finalUncert.relativeUncert = np.zeros(np.shape(finalUncert.totalUncert))*np.nan\n",
    "\n",
    "    #set novalid gridpoints to missing\n",
    "    finalBaseInterpUncert[grid.mask<=0] = -999\n",
    "    finalSlopeUncert[grid.mask<=0] = -999\n",
    "    finalUncert.totalUncert[grid.mask<=0] = -999\n",
    "    finalUncert.relativeUncert[grid.mask<=0] = -999   \n",
    "\n",
    "    #define components in output structure\n",
    "    finalUncert.finalBaseInterpUncert = finalBaseInterpUncert\n",
    "    finalUncert.finalSlopeUncert = finalSlopeUncert\n",
    " \n",
    "    \n",
    "    return finalUncert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d796a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with pass 1, row: 134\n",
      "\n",
      "0 points modified\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\askarzam\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\askarzam\\AppData\\Local\\Temp/ipykernel_5312/1505896360.py:111: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = np.cov(subBaseInterp[np.isnan(subBaseInterp)==False],subSlope[np.isnan(subSlope)==False])\n",
      "C:\\Users\\askarzam\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    }
   ],
   "source": [
    "#update and compute final fields conditioned on met variable\n",
    "if controlVars.variableEstimated=='precip':\n",
    "    #re-compute slope estimate\n",
    "    finalNormSlope = updatePrecipSlope(grid.nr,grid.nc,grid.mask,metGrid.normSlope,metGrid.validRegress,\\\n",
    "                                       parameters.defaultSlope,parameters.recomputeDefaultPrecipSlope,\\\n",
    "                                       parameters.filterSize,parameters.filterSpread)\n",
    "    \n",
    "    #compute final field value\n",
    "    #feather precipitation generally following Daly et al. (1994)\n",
    "    metGrid.finalField = featherPrecip(parameters,grid.nr,grid.nc,grid.dx,grid.smoothDemKM,grid.mask,finalNormSlope,\\\n",
    "                                       metGrid.baseInterpField,metGrid.baseInterpElev)\n",
    "    \n",
    "    #compute final uncertainty estimate\n",
    "    finalUncert = calcFinalPrecipUncert(grid,metGrid.baseInterpUncert,metGrid.baseInterpElev,metGrid.normSlopeUncert,\\\n",
    "                                        metGrid.baseInterpField,parameters.filterSize,parameters.filterSpread,\\\n",
    "                                        parameters.covWindow)\n",
    "    \n",
    "    #set metGrid variables\n",
    "    metGrid.finalSlope = finalNormSlope*metGrid.finalField\n",
    "    metGrid.finalSlope[grid.mask<0] = -999 #set final slope value to missing where mask is ocean\n",
    "    metGrid.totalUncert = finalUncert.totalUncert\n",
    "    metGrid.relUncert = finalUncert.relativeUncert\n",
    "    metGrid.baseInterpUncert = finalUncert.finalBaseInterpUncert\n",
    "    metGrid.slopeUncert = finalUncert.finalSlopeUncert\n",
    "    metGrid.defaultSlope = np.ones([grid.nc,grid.nr])*parameters.defaultSlope\n",
    "\n",
    "elif (controlVars.variableEstimated=='tmax') or (controlVars.variableEstimated=='tmin'):\n",
    "    #re-compute slope estimate\n",
    "    metGrid.finalSlope = updateTempSlope(grid.nr,grid.nc,grid.mask,grid.layerMask,metGrid.slope,\\\n",
    "                                         parameters.recomputeDefaultTempSlope,metGrid.defaultSlope,metGrid.validRegress,\\\n",
    "                                         parameters.minSlope,parameters.maxSlopeLower,parameters.maxSlopeUpper,\\\n",
    "                                         parameters.filterSize,parameters.filterSpread)\n",
    "\n",
    "    #compute final field estimate\n",
    "    metGrid.finalField = calcFinalTemp(grid.smoothDemKM,grid.mask,metGrid.baseInterpElev,metGrid.baseInterpField,\\\n",
    "                                       metGrid.finalSlope)\n",
    "    \n",
    "    #compute final uncertainty estimate\n",
    "    finalUncert = calcFinalTempUncert(grid,metGrid.baseInterpUncert,metGrid.baseInterpElev,metGrid.slopeUncert,\\\n",
    "                                      parameters.filterSize,parameters.filterSpread,parameters.covWindow)\n",
    "\n",
    "    #set metGrid variables\n",
    "    metGrid.totalUncert = finalUncert.totalUncert\n",
    "    metGrid.relUncert = finalUncert.relativeUncert\n",
    "    metGrid.baseInterpUncert = finalUncert.finalBaseInterpUncert\n",
    "    metGrid.slopeUncert = finalUncert.finalSlopeUncert\n",
    "    metGrid.defaultSlope = tempDefaultLapse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f5a99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove C:\\Users\\askarzam\\Downloads\\TIER-master\\data\\output\\caliOutput_prcp_13sta_test.nc\n"
     ]
    }
   ],
   "source": [
    "outputName=controlVars.outputName\n",
    "outputVar=controlVars.variableEstimated\n",
    "\n",
    "#size of grid\n",
    "nc,nr = np.shape(metGrid.rawField)\n",
    "\n",
    "#units check\n",
    "if outputVar=='precip':\n",
    "    physicalUnits = 'mm/day'\n",
    "    normSlopeUnits = 'km-1'\n",
    "    slopeUnits = 'mm/km'\n",
    "elif (outputVar=='tmax') or (outputVar=='tmin'):\n",
    "    physicalUnits = 'deg_C'\n",
    "    slopeUnits = 'deg_C/km'\n",
    "    normSlopeUnits = 'undefined'\n",
    "\n",
    "#check to see if output file name exists\n",
    "#if it does remove it and rewrite\n",
    "if os.path.isfile(outputName)== True:\n",
    "    #create string for system call\n",
    "    print('remove %s' %outputName)\n",
    "    os.remove(outputName)\n",
    "    \n",
    "try: ncfile.close()  # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "\n",
    "\n",
    "#Save to netcdf file\n",
    "#add grid fields first\n",
    "#create file, set dimensions and write elevation\n",
    "ncfile = Dataset(controlVars.outputName,mode='w',format='NETCDF4_CLASSIC') \n",
    "ncfile.createDimension('longitude',  nc)     \n",
    "ncfile.createDimension('latitude',  nr)\n",
    "\n",
    "\n",
    "# Create the attributes   of elevation  \n",
    "elevation = ncfile.createVariable('elevation', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "elevation.setncattr('name','Domain elevation')\n",
    "elevation.setncattr('long_name','Domain elevation')\n",
    "elevation.setncattr('units','m')\n",
    "# Appends data along unlimited dimension   \n",
    "elevation[:,:] = grid.dem*1000 #convert back to m\n",
    "\n",
    "\n",
    "latitude = ncfile.createVariable('latitude', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "latitude.setncattr('name','latitude')\n",
    "latitude.setncattr('long_name','latitude')\n",
    "latitude.setncattr('units','degrees_north')\n",
    "latitude[:,:] = grid.lat\n",
    "\n",
    "\n",
    "longitude= ncfile.createVariable('longitude', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "longitude.setncattr('name','longitude')\n",
    "longitude.setncattr('long_name','longitude')\n",
    "longitude.setncattr('units','degrees_west')\n",
    "longitude[:,:] = grid.lon\n",
    "\n",
    "mask= ncfile.createVariable('mask', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "mask.setncattr('name','Domain mask')\n",
    "mask.setncattr('long_name','Mask that sets land (1, valid), ocean (-1, met values not computed), and inland lake (0, met values computed)')\n",
    "mask.setncattr('units','-')\n",
    "mask[:,:] = grid.mask\n",
    "\n",
    "#now on to output variables from the TIER model\n",
    "#rawField\n",
    "rawField= ncfile.createVariable('rawField', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "rawField.setncattr('name','raw variable output')\n",
    "rawField.setncattr('long_name','Raw variable output before slope and gradient adjustments')\n",
    "rawField.setncattr('units',physicalUnits)\n",
    "rawField[:,:] = metGrid.rawField\n",
    "\n",
    "#intercept\n",
    "intercept= ncfile.createVariable('intercept', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "\n",
    "intercept.setncattr('name','intercept parameter')\n",
    "intercept.setncattr('long_name','Intercept parameter from the variable-elevation regression')\n",
    "intercept.setncattr('units',physicalUnits)\n",
    "intercept[:,:] = metGrid.intercept\n",
    "\n",
    "#slope\n",
    "slope= ncfile.createVariable('slope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "slope.setncattr('name','variable elevation slope')\n",
    "slope.setncattr('long_name','Raw variable elevation slope before slope adjustments')\n",
    "slope.setncattr('units',slopeUnits)\n",
    "slope[:,:] = metGrid.slope\n",
    "\n",
    "#normalized slope (valid for precipitation only)\n",
    "#normSlope\n",
    "normSlope= ncfile.createVariable('normSlope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "normSlope.setncattr('name','normalized variable slope')\n",
    "normSlope.setncattr('long_name','normalized variable elevation slope before slope adjustments(valid for precipitation only)')\n",
    "normSlope.setncattr('units',normSlopeUnits)\n",
    "normSlope[:,:] = metGrid.normSlope\n",
    "\n",
    "#baseInterpField\n",
    "baseInterpField= ncfile.createVariable('baseInterpField', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "baseInterpField.setncattr('name','baseInterp estimate')\n",
    "baseInterpField.setncattr('long_name','baseInterp estimated variable values on grid')\n",
    "baseInterpField.setncattr('units',physicalUnits)\n",
    "baseInterpField[:,:] = metGrid.baseInterpField\n",
    "\n",
    "#baseInterpElev\n",
    "baseInterpElev=ncfile.createVariable('baseInterpElev', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "baseInterpElev.setncattr('name','Weighted elevation')\n",
    "baseInterpElev.setncattr('long_name','Grid point elevation estimate using station elevations and final weights')\n",
    "baseInterpElev.setncattr('units','m')\n",
    "baseInterpElev[:,:] = metGrid.baseInterpElev\n",
    "\n",
    "#baseInterpUncert\n",
    "baseInterpUncert= ncfile.createVariable('baseInterpUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "baseInterpUncert.setncattr('name','baseInterp uncertainty')\n",
    "baseInterpUncert.setncattr('long_name','Uncertainty estimate from the baseInterp variable estimate')\n",
    "baseInterpUncert.setncattr('units',physicalUnits)\n",
    "baseInterpUncert[:,:] = metGrid.baseInterpUncert\n",
    "\n",
    "\n",
    "#slopeUncert\n",
    "slopeUncert= ncfile.createVariable('slopeUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "slopeUncert.setncattr('name','slope uncertainty')\n",
    "slopeUncert.setncattr('long_name','Uncertainty estimate (physical space) resulting from the variable-elevation slope estimate')\n",
    "slopeUncert.setncattr('units',physicalUnits)\n",
    "slopeUncert[:,:] = metGrid.slopeUncert\n",
    "\n",
    "#normSlopeUncert (valid for precipitation only)\n",
    "normSlopeUncert = ncfile.createVariable('normSlopeUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "normSlopeUncert.setncattr('name','normalized slope uncertainty')\n",
    "normSlopeUncert.setncattr('long_name','Uncertainty estimate (normalized) resulting from the variable-elevation slope estimate(valid for precipitation only)')\n",
    "normSlopeUncert.setncattr('units',normSlopeUnits)\n",
    "baseInterpUncert[:,:] = metGrid.normSlopeUncert\n",
    "\n",
    "#defaultSlope\n",
    "defaultSlope= ncfile.createVariable('defaultSlope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "defaultSlope.setncattr('name','default slope')\n",
    "defaultSlope.setncattr('long_name','default elevation-variable slope estimate')\n",
    "defaultSlope.setncattr('units',slopeUnits)\n",
    "defaultSlope[:,:] = metGrid.defaultSlope\n",
    "\n",
    "#finalSlope\n",
    "finalSlope= ncfile.createVariable('finalSlope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "finalSlope.setncattr('name','final slope')\n",
    "finalSlope.setncattr('long_name','Final variable elevation slope after slope adjustments')\n",
    "finalSlope.setncattr('units',slopeUnits)\n",
    "finalSlope[:,:] = metGrid.finalSlope\n",
    "\n",
    "#finalField\n",
    "finalField= ncfile.createVariable('finalField', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "finalField.setncattr('name','final variable output')\n",
    "finalField.setncattr('long_name','Final variable output after slope and gradient adjustments')\n",
    "finalField.setncattr('units',physicalUnits)\n",
    "finalField[:,:] = metGrid.finalField\n",
    "\n",
    "#totalUncert\n",
    "totalUncert= ncfile.createVariable('totalUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "totalUncert.setncattr('name','total uncertainty')\n",
    "totalUncert.setncattr('long_name','total uncertainty in physical units')\n",
    "totalUncert.setncattr('units',physicalUnits)\n",
    "totalUncert[:,:] = metGrid.totalUncert\n",
    "\n",
    "#relUncert\n",
    "relUncert= ncfile.createVariable('relUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "relUncert.setncattr('name','relative uncertainty')\n",
    "relUncert.setncattr('long_name','relative total uncertainty')\n",
    "relUncert.setncattr('units','-')\n",
    "relUncert[:,:] = metGrid.relUncert\n",
    "\n",
    "#validRegress\n",
    "validRegress=ncfile.createVariable('validRegress', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "validRegress.setncattr('name','valid regression')\n",
    "validRegress.setncattr('long_name','flag denoting the elevation-variable regression produced a valid slope')\n",
    "validRegress.setncattr('units','-')\n",
    "validRegress[:,:] = metGrid.validRegress\n",
    "\n",
    "#save parameters to output file as well\n",
    "#write this out as global attributes\n",
    "ncfile.nMaxNear=parameters.nMaxNear\n",
    "ncfile.nMaxNear =parameters.nMaxNear\n",
    "ncfile.nMinNear=parameters.nMinNear\n",
    "ncfile.maxDist=parameters.maxDist\n",
    "ncfile.minSlope=parameters.minSlope\n",
    "ncfile.maxInitialSlope= parameters.maxInitialSlope\n",
    "ncfile.maxFinalSlope=parameters.maxFinalSlope\n",
    "ncfile.maxSlopeLower=parameters.maxSlopeLower\n",
    "ncfile.maxSlopeUpper=parameters.maxSlopeUpper\n",
    "ncfile.defaultSlope=parameters.defaultSlope\n",
    "ncfile.topoPosMinDiff=parameters.topoPosMinDiff\n",
    "ncfile.topoPosMaxDiff =parameters.topoPosMaxDiff\n",
    "ncfile.topoPosExp =parameters.topoPosExp\n",
    "ncfile.costalExp =parameters.coastalExp\n",
    "ncfile.layerExp =parameters.layerExp\n",
    "ncfile.distanceWeightScale =parameters.distanceWeightScale\n",
    "ncfile.distanceWeightExp =parameters.distanceWeightExp\n",
    "ncfile.maxGrad =parameters.maxGrad\n",
    "ncfile.bufferSlope =parameters.bufferSlope\n",
    "ncfile.minElev =parameters.minElev\n",
    "ncfile.minElevDiff =parameters.minElevDiff\n",
    "ncfile.recomputeDefaultPrecipSlope = parameters.recomputeDefaultPrecipSlope\n",
    "ncfile.filterSize =parameters.filterSize\n",
    "ncfile.filterSpread =parameters.filterSpread\n",
    "ncfile.covWindow =parameters.covWindow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8cae9",
   "metadata": {},
   "source": [
    "# saveOutput:\n",
    "* *saves the metGrid structure into a netcdf file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d69dba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveOutput(outputName,outputVar,grid,metGrid,parameters):\n",
    "    \"\"\"\n",
    "     saveOutput saves the metGrid structure into a netcdf file\n",
    "\n",
    "     Arguments:\n",
    "\n",
    "      Input: outputName, string   , name of output file\n",
    "       metGrid, structure, structure containing TIER met fields\n",
    "\n",
    "      Output: None\n",
    "\n",
    "        Author: Andrew Newman, NCAR/RAL and Mozhgan A. Farahani SIParCs Intern\n",
    "        Email : anewman@ucar.edu & mozhgana@ucar.edu\n",
    "\n",
    "     Copyright (C) 2019 University Corporation for Atmospheric Research\n",
    "\n",
    "     This file is part of TIER.\n",
    "\n",
    "     TIER is free software: you can redistribute it and/or modify\n",
    "     it under the terms of the GNU General Public License as published by\n",
    "     the Free Software Foundation, either version 3 of the License, or\n",
    "     (at your option) any later version.\n",
    "\n",
    "     TIER is distributed in the hope that it will be useful,\n",
    "     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "     GNU General Public License for more details.\n",
    "\n",
    "     You should have received a copy of the GNU General Public License\n",
    "     along with TIER.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "    \"\"\"\n",
    "    #size of grid\n",
    "    nc,nr = np.shape(metGrid.rawField)\n",
    "\n",
    "    #units check\n",
    "    if outputVar=='precip':\n",
    "        physicalUnits = 'mm/day'\n",
    "        normSlopeUnits = 'km-1'\n",
    "        slopeUnits = 'mm/km'\n",
    "    elif (outputVar=='tmax') or (outputVar=='tmin'):\n",
    "        physicalUnits = 'deg_C'\n",
    "        slopeUnits = 'deg_C/km'\n",
    "        normSlopeUnits = 'undefined'\n",
    "\n",
    "    #check to see if output file name exists\n",
    "    #if it does remove it and rewrite\n",
    "    if os.path.isfile(outputName)== True:\n",
    "        #create string for system call\n",
    "        print('remove %s' %outputName)\n",
    "        os.remove(outputName)\n",
    "\n",
    "    try: ncfile.close()  # just to be safe, make sure dataset is not already open.\n",
    "    except: pass\n",
    "\n",
    "\n",
    "    #Save to netcdf file\n",
    "    #add grid fields first\n",
    "    #create file, set dimensions and write elevation\n",
    "    ncfile = Dataset(controlVars.outputName,mode='w',format='NETCDF4_CLASSIC') \n",
    "    ncfile.createDimension('longitude',  nc)     \n",
    "    ncfile.createDimension('latitude',  nr)\n",
    "\n",
    "\n",
    "    # Create the attributes   of elevation  \n",
    "    elevation = ncfile.createVariable('elevation', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    elevation.setncattr('name','Domain elevation')\n",
    "    elevation.setncattr('long_name','Domain elevation')\n",
    "    elevation.setncattr('units','m')\n",
    "    # Appends data along unlimited dimension   \n",
    "    elevation[:,:] = grid.dem*1000 #convert back to m\n",
    "\n",
    "\n",
    "    latitude = ncfile.createVariable('latitude', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    latitude.setncattr('name','latitude')\n",
    "    latitude.setncattr('long_name','latitude')\n",
    "    latitude.setncattr('units','degrees_north')\n",
    "    latitude[:,:] = grid.lat\n",
    "\n",
    "\n",
    "    longitude= ncfile.createVariable('longitude', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    longitude.setncattr('name','longitude')\n",
    "    longitude.setncattr('long_name','longitude')\n",
    "    longitude.setncattr('units','degrees_west')\n",
    "    longitude[:,:] = grid.lon\n",
    "\n",
    "    mask= ncfile.createVariable('mask', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    mask.setncattr('name','Domain mask')\n",
    "    mask.setncattr('long_name','Mask that sets land (1, valid), ocean (-1, met values not computed), and inland lake (0, met values computed)')\n",
    "    mask.setncattr('units','-')\n",
    "    mask[:,:] = grid.mask\n",
    "\n",
    "    #now on to output variables from the TIER model\n",
    "    #rawField\n",
    "    rawField= ncfile.createVariable('rawField', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    rawField.setncattr('name','raw variable output')\n",
    "    rawField.setncattr('long_name','Raw variable output before slope and gradient adjustments')\n",
    "    rawField.setncattr('units',physicalUnits)\n",
    "    rawField[:,:] = metGrid.rawField\n",
    "\n",
    "    #intercept\n",
    "    intercept= ncfile.createVariable('intercept', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "\n",
    "    intercept.setncattr('name','intercept parameter')\n",
    "    intercept.setncattr('long_name','Intercept parameter from the variable-elevation regression')\n",
    "    intercept.setncattr('units',physicalUnits)\n",
    "    intercept[:,:] = metGrid.intercept\n",
    "\n",
    "    #slope\n",
    "    slope= ncfile.createVariable('slope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    slope.setncattr('name','variable elevation slope')\n",
    "    slope.setncattr('long_name','Raw variable elevation slope before slope adjustments')\n",
    "    slope.setncattr('units',slopeUnits)\n",
    "    slope[:,:] = metGrid.slope\n",
    "\n",
    "    #normalized slope (valid for precipitation only)\n",
    "    #normSlope\n",
    "    normSlope= ncfile.createVariable('normSlope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    normSlope.setncattr('name','normalized variable slope')\n",
    "    normSlope.setncattr('long_name','normalized variable elevation slope before slope adjustments(valid for precipitation only)')\n",
    "    normSlope.setncattr('units',normSlopeUnits)\n",
    "    normSlope[:,:] = metGrid.normSlope\n",
    "\n",
    "    #baseInterpField\n",
    "    baseInterpField= ncfile.createVariable('baseInterpField', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    baseInterpField.setncattr('name','baseInterp estimate')\n",
    "    baseInterpField.setncattr('long_name','baseInterp estimated variable values on grid')\n",
    "    baseInterpField.setncattr('units',physicalUnits)\n",
    "    baseInterpField[:,:] = metGrid.baseInterpField\n",
    "\n",
    "    #baseInterpElev\n",
    "    baseInterpElev=ncfile.createVariable('baseInterpElev', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    baseInterpElev.setncattr('name','Weighted elevation')\n",
    "    baseInterpElev.setncattr('long_name','Grid point elevation estimate using station elevations and final weights')\n",
    "    baseInterpElev.setncattr('units','m')\n",
    "    baseInterpElev[:,:] = metGrid.baseInterpElev\n",
    "\n",
    "    #baseInterpUncert\n",
    "    baseInterpUncert= ncfile.createVariable('baseInterpUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    baseInterpUncert.setncattr('name','baseInterp uncertainty')\n",
    "    baseInterpUncert.setncattr('long_name','Uncertainty estimate from the baseInterp variable estimate')\n",
    "    baseInterpUncert.setncattr('units',physicalUnits)\n",
    "    baseInterpUncert[:,:] = metGrid.baseInterpUncert\n",
    "\n",
    "\n",
    "    #slopeUncert\n",
    "    slopeUncert= ncfile.createVariable('slopeUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    slopeUncert.setncattr('name','slope uncertainty')\n",
    "    slopeUncert.setncattr('long_name','Uncertainty estimate (physical space) resulting from the variable-elevation slope estimate')\n",
    "    slopeUncert.setncattr('units',physicalUnits)\n",
    "    slopeUncert[:,:] = metGrid.slopeUncert\n",
    "\n",
    "    #normSlopeUncert (valid for precipitation only)\n",
    "    normSlopeUncert = ncfile.createVariable('normSlopeUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    normSlopeUncert.setncattr('name','normalized slope uncertainty')\n",
    "    normSlopeUncert.setncattr('long_name','Uncertainty estimate (normalized) resulting from the variable-elevation slope estimate(valid for precipitation only)')\n",
    "    normSlopeUncert.setncattr('units',normSlopeUnits)\n",
    "    baseInterpUncert[:,:] = metGrid.normSlopeUncert\n",
    "\n",
    "    #defaultSlope\n",
    "    defaultSlope= ncfile.createVariable('defaultSlope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    defaultSlope.setncattr('name','default slope')\n",
    "    defaultSlope.setncattr('long_name','default elevation-variable slope estimate')\n",
    "    defaultSlope.setncattr('units',slopeUnits)\n",
    "    defaultSlope[:,:] = metGrid.defaultSlope\n",
    "\n",
    "    #finalSlope\n",
    "    finalSlope= ncfile.createVariable('finalSlope', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    finalSlope.setncattr('name','final slope')\n",
    "    finalSlope.setncattr('long_name','Final variable elevation slope after slope adjustments')\n",
    "    finalSlope.setncattr('units',slopeUnits)\n",
    "    finalSlope[:,:] = metGrid.finalSlope\n",
    "\n",
    "    #finalField\n",
    "    finalField= ncfile.createVariable('finalField', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    finalField.setncattr('name','final variable output')\n",
    "    finalField.setncattr('long_name','Final variable output after slope and gradient adjustments')\n",
    "    finalField.setncattr('units',physicalUnits)\n",
    "    finalField[:,:] = metGrid.finalField\n",
    "\n",
    "    #totalUncert\n",
    "    totalUncert= ncfile.createVariable('totalUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    totalUncert.setncattr('name','total uncertainty')\n",
    "    totalUncert.setncattr('long_name','total uncertainty in physical units')\n",
    "    totalUncert.setncattr('units',physicalUnits)\n",
    "    totalUncert[:,:] = metGrid.totalUncert\n",
    "\n",
    "    #relUncert\n",
    "    relUncert= ncfile.createVariable('relUncert', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    relUncert.setncattr('name','relative uncertainty')\n",
    "    relUncert.setncattr('long_name','relative total uncertainty')\n",
    "    relUncert.setncattr('units','-')\n",
    "    relUncert[:,:] = metGrid.relUncert\n",
    "\n",
    "    #validRegress\n",
    "    validRegress=ncfile.createVariable('validRegress', np.float64,('longitude','latitude'), fill_value= -999.0)\n",
    "    validRegress.setncattr('name','valid regression')\n",
    "    validRegress.setncattr('long_name','flag denoting the elevation-variable regression produced a valid slope')\n",
    "    validRegress.setncattr('units','-')\n",
    "    validRegress[:,:] = metGrid.validRegress\n",
    "\n",
    "    #save parameters to output file as well\n",
    "    #write this out as global attributes\n",
    "    ncfile.nMaxNear=parameters.nMaxNear\n",
    "    ncfile.nMaxNear =parameters.nMaxNear\n",
    "    ncfile.nMinNear=parameters.nMinNear\n",
    "    ncfile.maxDist=parameters.maxDist\n",
    "    ncfile.minSlope=parameters.minSlope\n",
    "    ncfile.maxInitialSlope= parameters.maxInitialSlope\n",
    "    ncfile.maxFinalSlope=parameters.maxFinalSlope\n",
    "    ncfile.maxSlopeLower=parameters.maxSlopeLower\n",
    "    ncfile.maxSlopeUpper=parameters.maxSlopeUpper\n",
    "    ncfile.defaultSlope=parameters.defaultSlope\n",
    "    ncfile.topoPosMinDiff=parameters.topoPosMinDiff\n",
    "    ncfile.topoPosMaxDiff =parameters.topoPosMaxDiff\n",
    "    ncfile.topoPosExp =parameters.topoPosExp\n",
    "    ncfile.costalExp =parameters.coastalExp\n",
    "    ncfile.layerExp =parameters.layerExp\n",
    "    ncfile.distanceWeightScale =parameters.distanceWeightScale\n",
    "    ncfile.distanceWeightExp =parameters.distanceWeightExp\n",
    "    ncfile.maxGrad =parameters.maxGrad\n",
    "    ncfile.bufferSlope =parameters.bufferSlope\n",
    "    ncfile.minElev =parameters.minElev\n",
    "    ncfile.minElevDiff =parameters.minElevDiff\n",
    "    ncfile.recomputeDefaultPrecipSlope = parameters.recomputeDefaultPrecipSlope\n",
    "    ncfile.filterSize =parameters.filterSize\n",
    "    ncfile.filterSpread =parameters.filterSpread\n",
    "    ncfile.covWindow =parameters.covWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae4fcd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove C:\\Users\\askarzam\\Downloads\\TIER-master\\data\\output\\caliOutput_prcp_13sta_test.nc\n"
     ]
    }
   ],
   "source": [
    "ncfile.close()  # just to be safe, make sure dataset is not already open.\n",
    "\n",
    "#output\n",
    "saveOutput(controlVars.outputName,controlVars.variableEstimated,grid,metGrid,parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
